"use strict";(self.webpackChunkkoordinator_sh=self.webpackChunkkoordinator_sh||[]).push([[2157],{3905:(e,n,o)=>{o.d(n,{Zo:()=>u,kt:()=>g});var t=o(7294);function r(e,n,o){return n in e?Object.defineProperty(e,n,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[n]=o,e}function a(e,n){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),o.push.apply(o,t)}return o}function s(e){for(var n=1;n<arguments.length;n++){var o=null!=arguments[n]?arguments[n]:{};n%2?a(Object(o),!0).forEach((function(n){r(e,n,o[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):a(Object(o)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(o,n))}))}return e}function i(e,n){if(null==e)return{};var o,t,r=function(e,n){if(null==e)return{};var o,t,r={},a=Object.keys(e);for(t=0;t<a.length;t++)o=a[t],n.indexOf(o)>=0||(r[o]=e[o]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(t=0;t<a.length;t++)o=a[t],n.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(r[o]=e[o])}return r}var l=t.createContext({}),c=function(e){var n=t.useContext(l),o=n;return e&&(o="function"==typeof e?e(n):s(s({},n),e)),o},u=function(e){var n=c(e.components);return t.createElement(l.Provider,{value:n},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},m=t.forwardRef((function(e,n){var o=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),d=c(o),m=r,g=d["".concat(l,".").concat(m)]||d[m]||p[m]||a;return o?t.createElement(g,s(s({ref:n},u),{},{components:o})):t.createElement(g,s({ref:n},u))}));function g(e,n){var o=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=o.length,s=new Array(a);s[0]=m;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i[d]="string"==typeof e?e:r,s[1]=i;for(var c=2;c<a;c++)s[c]=o[c];return t.createElement.apply(null,s)}return t.createElement.apply(null,o)}m.displayName="MDXCreateElement"},2:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>c});var t=o(7462),r=(o(7294),o(3905));const a={},s="Enhanced NodeResourceFit",i={unversionedId:"user-manuals/node-resource-fit-plus-scoring",id:"user-manuals/node-resource-fit-plus-scoring",title:"Enhanced NodeResourceFit",description:"Introduction",source:"@site/docs/user-manuals/node-resource-fit-plus-scoring.md",sourceDirName:"user-manuals",slug:"/user-manuals/node-resource-fit-plus-scoring",permalink:"/docs/next/user-manuals/node-resource-fit-plus-scoring",draft:!1,editUrl:"https://github.com/koordinator-sh/koordinator.sh/edit/main/docs/user-manuals/node-resource-fit-plus-scoring.md",tags:[],version:"current",lastUpdatedBy:"wangjianyu",lastUpdatedAt:1740707377,formattedLastUpdatedAt:"Feb 28, 2025",frontMatter:{},sidebar:"docs",previous:{title:"Device Scheduling - cambricon-mlu",permalink:"/docs/next/user-manuals/device-scheduling-cambricon-mlu"},next:{title:"Load Aware Scheduling",permalink:"/docs/next/user-manuals/load-aware-scheduling"}},l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Plugin Logic Explanation",id:"plugin-logic-explanation",level:2},{value:"NodeResourcesFitPlus",id:"noderesourcesfitplus",level:3},{value:"ScarceResourceAvoidance",id:"scarceresourceavoidance",level:3},{value:"Example",id:"example",level:2},{value:"SchedulerConfiguration Example",id:"schedulerconfiguration-example",level:3},{value:"GPU Applications And Node Score",id:"gpu-applications-and-node-score",level:3},{value:"CPU Applications And Node Score",id:"cpu-applications-and-node-score",level:3},{value:"Compatible With Native NodeResourceFit",id:"compatible-with-native-noderesourcefit",level:2},{value:"MostAllocated",id:"mostallocated",level:3},{value:"LeastAllocated",id:"leastallocated",level:3}],u={toc:c},d="wrapper";function p(e){let{components:n,...a}=e;return(0,r.kt)(d,(0,t.Z)({},u,a,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"enhanced-noderesourcefit"},"Enhanced NodeResourceFit"),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,"The NodeResourcesFit plugin of native k8s can only adopt a type of strategy for all resources, such as MostRequestedPriority and LeastRequestedPriority. However, in industrial practice, this design does not apply to some scenarios. For example:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"In AI scenarios, pods that apply for GPUs prefer to occupy the entire GPU machine first to prevent GPU fragmentation. "),(0,r.kt)("li",{parentName:"ol"},"Pods that apply for CPU and memory are prioritized and dispersed to non-GPU machines to prevent excessive consumption of CPU and memory on GPU machines, resulting in real tasks that require GPUs pending due to insufficient non-GPU resources.")),(0,r.kt)("p",null,"It is therefore hoped that both strategies can be provided to address this business need. Koordinator provides the NodeResourcesFitPlus and ScarceResourceAvoidance plugins to support the requirements of these two scenarios, thereby:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Different types of resources can be configured with different strategies to prioritize them in the form of weights"),(0,r.kt)("li",{parentName:"ul"},"Prevent pods that have not applied for scarce resources from being scheduled to nodes with scarce resources.")),(0,r.kt)("h2",{id:"plugin-logic-explanation"},"Plugin Logic Explanation"),(0,r.kt)("h3",{id:"noderesourcesfitplus"},"NodeResourcesFitPlus"),(0,r.kt)("p",null,"The scheduler args for the  NodeResourcesFitPlus plugin can be configured as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"resources: \n  nvidia.com/gpu:\n    type: MostAllocated\n    weight: 2\n  cpu:\n    type: LeastAllocated\n    weight: 1\n  memory:\n    type: LeastAllocated\n    weight: 1\n")),(0,r.kt)("p",null,"The two strategies have the following score calculation methods and effects:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"image",src:o(165).Z,width:"645",height:"148"})),(0,r.kt)("p",null,"The final node score can be calculated as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"finalScoreNode = [(weight1 * resource1) + (weight2 * resource2) + \u2026 + (weightN* resourceN)] /(weight1+weight2+ \u2026 +weightN)\n")),(0,r.kt)("h3",{id:"scarceresourceavoidance"},"ScarceResourceAvoidance"),(0,r.kt)("p",null,"The scheduler args for the ScarceResourceAvoidance plugin can be configured as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"resources: \n- nvidia.com/gpu\n- scarceResource1\n- scarceResource2\n")),(0,r.kt)("p",null,"After obtaining scarce resource types from the config, the plugin will score the node and Pod fitness as follows:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Obtain the set of resource types requested by the pod and the set of resource types that the node can allocate."),(0,r.kt)("li",{parentName:"ol"},"ResourceTypesUnused = ResourceTypesTotal - ResourceTypesRequested"),(0,r.kt)("li",{parentName:"ol"},"ScarceResourceTypesUnused = intersection(ResourceTypesUnused, ScarceResourceTypes)")),(0,r.kt)("p",null,"The more unused scarce resource types, the lower the score will be."),(0,r.kt)("h2",{id:"example"},"Example"),(0,r.kt)("h3",{id:"schedulerconfiguration-example"},"SchedulerConfiguration Example"),(0,r.kt)("p",null,"We can configure schedulerConfiguration as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'profiles:\n- pluginConfig:\n  - args:\n      apiVersion: kubescheduler.config.k8s.io/v1\n      kind: NodeResourcesFitPlusArgs\n      resources: \n        nvidia.com/gpu:\n          type: MostAllocated\n          weight: 2\n        cpu:\n          type: LeastAllocated\n          weight: 1\n        memory:\n          type: LeastAllocated\n          weight: 1\n    name: NodeResourcesFitPlus\n  - args:\n      apiVersion: kubescheduler.config.k8s.io/v1\n      kind: ScarceResourceAvoidanceArgs\n      resources: \n      - nvidia.com/gpu\n    name: ScarceResourceAvoidance\n  plugins:\n    score:\n      enabled:\n      - name: NodeResourcesFitPlus\n        weight: 2\n      - name: ScarceResourceAvoidance\n        weight: 2\n      disabled:\n      - name: "*"\n  schedulerName: koord-scheduler\n')),(0,r.kt)("h3",{id:"gpu-applications-and-node-score"},"GPU Applications And Node Score"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-scheduler1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: test-scheduler1\n  template:\n    metadata:\n      labels:\n        app: test-scheduler1\n    spec:\n      schedulerName: koord-scheduler\n      containers:\n        - image: dockerpull.com/nginx\n          imagePullPolicy: IfNotPresent\n          name: nginx\n          ports:\n            - containerPort: 80\n          resources:\n            requests:\n              cpu: "100"\n              memory: "100"\n              nvidia.com/gpu: 2\n            limits:\n              cpu: "100"\n              memory: "100"\n              nvidia.com/gpu: 2\n')),(0,r.kt)("p",null,"Node allocation rate information"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"node1: cpu 58%, memory 21%, nvidia.com/gpu 6 (total 8)\n\nnode2: cpu 22%, memory 5%, nvidia.com/gpu 0 (total 8)\n")),(0,r.kt)("p",null,"Result: Prioritize GPU machines and pool GPU resources"),(0,r.kt)("p",null,"Log view => ",(0,r.kt)("inlineCode",{parentName:"p"},"Top10 scores for pod")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"| # | Pod | Node | Score | NodeResourcesFitPlus | ScarceResourceAvoidance |\n| 0 | test-scheduler1-xxx | node1 | 358 | 158 | 200 |\n| 1 | test-scheduler1-xxx | node2 | 296 | 96 | 200 |\n")),(0,r.kt)("h3",{id:"cpu-applications-and-node-score"},"CPU Applications And Node Score"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-scheduler1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: test-scheduler1\n  template:\n    metadata:\n      labels:\n        app: test-scheduler1\n    spec:\n      schedulerName: koord-scheduler\n      containers:\n        - image: dockerpull.com/nginx\n          imagePullPolicy: IfNotPresent\n          name: nginx\n          ports:\n            - containerPort: 80\n          resources:\n            requests:\n              cpu: "100"\n              memory: "100"\n            limits:\n              cpu: "100"\n              memory: "100"\n')),(0,r.kt)("p",null,"Node allocation rate information"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"node1: cpu 22%, memory 10%, nvidia.com/gpu 6 (total 8)\nnode2: cpu 40%, memory 50%\nnode3: cpu 30%, memory 20%\n")),(0,r.kt)("p",null,"Result: Prioritize CPU machines and disperse CPU and MEM resources"),(0,r.kt)("p",null,"Log view => ",(0,r.kt)("inlineCode",{parentName:"p"},"Top10 scores for pod")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"| # | Pod | Node | Score | NodeResourcesFitPlus | ScarceResourceAvoidance |\n| 0 | test-scheduler1-xxx | node1 | 310 | 144 | 166 |\n| 1 | test-scheduler1-xxx | node2 | 262 | 62 | 200 |\n| 2 | test-scheduler1-xxx | node3 | 326 | 126 | 200 |\n")),(0,r.kt)("h2",{id:"compatible-with-native-noderesourcefit"},"Compatible With Native NodeResourceFit"),(0,r.kt)("h3",{id:"mostallocated"},"MostAllocated"),(0,r.kt)("p",null,"native configuration:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: scheduler-config\n  namespace: kube-system\ndata:\n  scheduler-config.yaml: |\n    apiVersion: kubescheduler.config.k8s.io/v1\n    kind: KubeSchedulerConfiguration\n    profiles:\n    - schedulerName: koord-scheduler\n     pluginConfig:\n       - args:\n           scoringStrategy:\n             resources:\n             - name: cpu\n               weight: 2\n             - name: memory\n               weight: 1\n             type: MostAllocated\n         name: NodeResourcesFit\n      plugins:\n        score:\n          enabled:\n          - name: "NodeResourcesFit"\n')),(0,r.kt)("p",null,"NodeResourcesFitPlus configuration:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: scheduler-config\n  namespace: kube-system\ndata:\n  scheduler-config.yaml: |\n    apiVersion: kubescheduler.config.k8s.io/v1\n    kind: KubeSchedulerConfiguration\n    profiles:\n    - schedulerName: koord-scheduler\n     pluginConfig:\n       - args:\n          apiVersion: kubescheduler.config.k8s.io/v1\n          kind: NodeResourcesFitPlusArgs\n          resources: \n            cpu:\n              type: MostAllocated\n              weight: 2\n            memory:\n              type: MostAllocated\n              weight: 1\n         name: NodeResourcesFitPlus\n      plugins:\n        score:\n          enabled:\n          - name: "NodeResourcesFitPlus"\n')),(0,r.kt)("h3",{id:"leastallocated"},"LeastAllocated"),(0,r.kt)("p",null,"native configuration:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: scheduler-config\n  namespace: kube-system\ndata:\n  scheduler-config.yaml: |\n    apiVersion: kubescheduler.config.k8s.io/v1\n    kind: KubeSchedulerConfiguration\n    profiles:\n    - schedulerName: koord-scheduler\n     pluginConfig:\n       - args:\n           scoringStrategy:\n             resources:\n             - name: cpu\n               weight: 2\n             - name: memory\n               weight: 1\n             type: LeastAllocated\n         name: NodeResourcesFit\n      plugins:\n        score:\n          enabled:\n          - name: "NodeResourcesFit"\n')),(0,r.kt)("p",null,"NodeResourcesFitPlus configuration:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: scheduler-config\n  namespace: kube-system\ndata:\n  scheduler-config.yaml: |\n    apiVersion: kubescheduler.config.k8s.io/v1\n    kind: KubeSchedulerConfiguration\n    profiles:\n    - schedulerName: koord-scheduler\n     pluginConfig:\n       - args:\n          apiVersion: kubescheduler.config.k8s.io/v1\n          kind: NodeResourcesFitPlus\n          resources: \n            cpu:\n              type: LeastAllocated\n              weight: 2\n            memory:\n              type: LeastAllocated\n              weight: 1\n         name: NodeResourcesFitPlus\n      plugins:\n        score:\n          enabled:\n          - name: "NodeResourcesFitPlus"\n')))}p.isMDXComponent=!0},165:(e,n,o)=>{o.d(n,{Z:()=>t});const t=o.p+"assets/images/node-resource-fit-plus-scoring-en-80725663002084486b4f0767766e69a6.png"}}]);