"use strict";(self.webpackChunkkoordinator_sh=self.webpackChunkkoordinator_sh||[]).push([[6922],{3905:(e,n,t)=>{t.d(n,{Zo:()=>l,kt:()=>v});var o=t(7294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,i=function(e,n){if(null==e)return{};var t,o,i={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var c=o.createContext({}),d=function(e){var n=o.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},l=function(e){var n=d(e.components);return o.createElement(c.Provider,{value:n},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},p=o.forwardRef((function(e,n){var t=e.components,i=e.mdxType,r=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),u=d(t),p=i,v=u["".concat(c,".").concat(p)]||u[p]||h[p]||r;return t?o.createElement(v,a(a({ref:n},l),{},{components:t})):o.createElement(v,a({ref:n},l))}));function v(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=t.length,a=new Array(r);a[0]=p;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s[u]="string"==typeof e?e:i,a[1]=s;for(var d=2;d<r;d++)a[d]=t[d];return o.createElement.apply(null,a)}return o.createElement.apply(null,t)}p.displayName="MDXCreateElement"},2349:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var o=t(7462),i=(t(7294),t(3905));const r={},a="Device",s={unversionedId:"architecture/device",id:"architecture/device",title:"Device",description:"Device is an abstraction of heterogeneous devices on a K8s node.",source:"@site/docs/architecture/device.md",sourceDirName:"architecture",slug:"/architecture/device",permalink:"/docs/next/architecture/device",draft:!1,editUrl:"https://github.com/koordinator-sh/koordinator.sh/edit/main/docs/architecture/device.md",tags:[],version:"current",lastUpdatedBy:"Zach Zhu",lastUpdatedAt:1760531856,formattedLastUpdatedAt:"Oct 15, 2025",frontMatter:{},sidebar:"docs",previous:{title:"Job",permalink:"/docs/next/architecture/job"},next:{title:"GangScheduling",permalink:"/docs/next/user-manuals/gang-scheduling"}},c={},d=[{value:"Definition",id:"definition",level:2},{value:"Device Scheduling Architecture",id:"device-scheduling-architecture",level:2},{value:"Heterogeneous Device Adaptation Extension Mechanism",id:"heterogeneous-device-adaptation-extension-mechanism",level:2},{value:"Devices with End-to-End Support",id:"devices-with-end-to-end-support",level:2},{value:"What\u2019s Next",id:"whats-next",level:2}],l={toc:d},u="wrapper";function h(e){let{components:n,...r}=e;return(0,i.kt)(u,(0,o.Z)({},l,r,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"device"},"Device"),(0,i.kt)("p",null,"Device is an abstraction of heterogeneous devices on a K8s node."),(0,i.kt)("h2",{id:"definition"},"Definition"),(0,i.kt)("p",null,"Device represents all heterogeneous devices on a K8s node, typically including GPU, RDMA, FPGA, etc. In a K8s cluster, it exists as a CRD. For every K8s Node, there is a corresponding Device object that contains basic information, resource details, topology information, and health status of all heterogeneous devices on that node. An example object is as follows:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.koordinator.sh/v1alpha1\nkind: Device\nmetadata:\n  name: worker01\n  labels:\n    node.koordinator.sh/gpu-model: NVIDIA-H20\n    node.koordinator.sh/gpu-vendor: nvidia\n  ...\nspec:\n  devices:\n  - conditions:\n    - lastTransitionTime: "2025-10-07T07:15:15Z"\n      message: device is healthy\n      reason: DeviceHealthy\n      status: "True"\n      type: Healthy\n    health: true\n    id: GPU-a43e0de9-28a0-1e87-32f8-f5c4994b3e69\n    minor: 0\n    resources:\n      koordinator.sh/gpu-core: "100"\n      koordinator.sh/gpu-memory: 97871Mi\n      koordinator.sh/gpu-memory-ratio: "100"\n    topology:\n      busID: 0000:0e:00.0\n      nodeID: 0\n      pcieID: pci0000:0b\n      socketID: -1\n    type: gpu\n  - conditions:\n    - lastTransitionTime: "2025-10-07T07:15:15Z"\n      message: device is healthy\n      reason: DeviceHealthy\n      status: "True"\n      type: Healthy\n    health: true\n    id: GPU-05308270-c34c-8a61-e8b2-aeefbc23a3ba\n    minor: 1\n    resources:\n      koordinator.sh/gpu-core: "100"\n      koordinator.sh/gpu-memory: 97871Mi\n      koordinator.sh/gpu-memory-ratio: "100"\n    topology:\n      busID: "0000:44:00.0"\n      nodeID: 0\n      pcieID: pci0000:3a\n      socketID: -1\n    type: gpu\n  - health: true\n    id: 0000:0f:00.0\n    minor: 0\n    resources:\n      koordinator.sh/rdma: "100"\n    topology:\n      busID: 0000:0f:00.0\n      nodeID: 0\n      pcieID: pci0000:0b\n      socketID: -1\n    type: rdma\n    vfGroups:\n    - vfs:\n      - busID: 0000:0f:00.1\n        minor: -1\n      - busID: 0000:0f:00.2\n        minor: -1\n      - busID: 0000:0f:00.3\n        minor: -1\n      - busID: 0000:0f:00.4\n        minor: -1\n      - busID: 0000:0f:00.5\n        minor: -1\n      - busID: 0000:0f:00.6\n        minor: -1\n      - busID: 0000:0f:00.7\n        minor: -1\n      - busID: 0000:0f:01.0\n        minor: -1\n  - health: true\n    id: 0000:3d:00.0\n    minor: 1\n    resources:\n      koordinator.sh/rdma: "100"\n    topology:\n      busID: 0000:3d:00.0\n      nodeID: 0\n      pcieID: pci0000:3a\n      socketID: -1\n    type: rdma\n    vfGroups:\n    - vfs:\n      - busID: 0000:3d:00.1\n        minor: -1\n      - busID: 0000:3d:00.2\n        minor: -1\n      - busID: 0000:3d:00.3\n        minor: -1\n      - busID: 0000:3d:00.4\n        minor: -1\n      - busID: 0000:3d:00.5\n        minor: -1\n      - busID: 0000:3d:00.6\n        minor: -1\n      - busID: 0000:3d:00.7\n        minor: -1\n      - busID: 0000:3d:01.0\n        minor: -1\n  ...\n')),(0,i.kt)("p",null,"This object is reported by koordlet. When koord-scheduler schedules Pods that request heterogeneous device resources, it uses this object to make various complex scheduling decisions, such as partial device resource allocation (vGPU), virtual device allocation (RDMA VF), topology-aware scheduling, and device fault isolation. Through Device, Koordinator achieves globally optimized scheduling for heterogeneous devices, overcoming the functional limitations of the traditional ",(0,i.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/"},"K8s device plugin")," approach where device allocation is handled by kubelet."),(0,i.kt)("h2",{id:"device-scheduling-architecture"},"Device Scheduling Architecture"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Device Scheduling Architecture",src:t(9062).Z,width:"2753",height:"1649"})),(0,i.kt)("p",null,"The figure above shows the component architecture and workflow of Koordinator device scheduling. The entire device scheduling process can be divided into three stages:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Device reporting: Mainly handled by koordlet and its accompanying koord-device-daemon. koord-manager also participates in this process. Currently, koordlet has built-in capabilities to collect and report information for NVIDIA GPUs and generic RDMA devices. For other vendors\u2019 heterogeneous GPUs (such as Huawei Ascend NPU, etc.), it reads Device Info files written by external components to collect and report device information, enabling flexible adaptation to various heterogeneous GPU devices. The extension mechanism will be further described below.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Device scheduling: Fully handled by the centralized koord-scheduler. It considers both Node and Device information, and makes globally optimal scheduling decisions based on Pod device resource requests. It supports advanced capabilities such as partial device resource allocation (vGPU), virtual device allocation (RDMA VF), topology-aware scheduling, and device fault isolation. Since Device provides a good abstraction for heterogeneous devices, the core device scheduling logic of koord-scheduler is vendor-agnostic and highly general. The scheduling results are eventually written into Pod annotations for node-side components to read. In addition, koord-scheduler provides an adapter mechanism for third-party vendor device plugins to seamlessly integrate with the existing device plugin ecosystem. This extension mechanism will be further described below.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Device allocation: Mainly handled by koordlet. It currently has built-in allocation capabilities for NVIDIA GPUs and generic RDMA devices. It reads koord-scheduler\u2019s device scheduling results from the Pod and injects the required device files and environment variables into the target container via the NRI mechanism. For NVIDIA GPUs, it integrates ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Project-HAMi/HAMi/"},"HAMi")," to provide virtual GPU allocation. For other third-party vendor heterogeneous GPUs, through the koord-scheduler device plugin adapter mechanism mentioned above, device allocation can directly use the vendor-provided device plugin and corresponding container runtime (if any)."))),(0,i.kt)("h2",{id:"heterogeneous-device-adaptation-extension-mechanism"},"Heterogeneous Device Adaptation Extension Mechanism"),(0,i.kt)("p",null,"Koordinator device scheduling provides an extension mechanism to minimize the onboarding cost of new devices. Below we take integrating a new vendor\u2019s GPU as an example to introduce this mechanism:"),(0,i.kt)("p",null,"First, we need koordlet to recognize and report this type of GPU. This can be achieved by writing a Device Info file on the node that contains information about all such GPUs on the node. This file includes the vendor, model, resources, topology, and health status of the GPUs. These details can be obtained in any way (e.g., via the GPU\u2019s CLI tools), as long as they are written according to the Device Info file format. koordlet will automatically detect the file and report it as a Device object. Koordinator currently provides a built-in koord-device-daemon component that can generate Device Info files for some third-party vendor GPUs. This component will continue to onboard new third-party GPUs, and contributions from the community are welcomed."),(0,i.kt)("p",null,"Since the core scheduling logic is generic, in most cases, whether using full GPUs or partial vGPUs, we do not need to modify koord-scheduler\u2019s core scheduling logic."),(0,i.kt)("p",null,"Finally, we need to integrate the node-side device allocation for this GPU. Since the vast majority of device vendors now provide K8s device plugins, we can directly use the vendor\u2019s official device plugin on the node side. The only required work is to add adapter code for this GPU device plugin in koord-scheduler\u2019s device plugin adaptation extension. Its role is to convert koord-scheduler\u2019s device scheduling result into the format recognized by the GPU\u2019s device plugin and write it into the Pod. Likewise, koord-scheduler already has built-in adaptation logic for some third-party GPUs and will continue to onboard new ones, with community contributions welcomed. Note, however, that if a third-party vendor\u2019s device plugin does not support scheduler-side device allocation, this integration approach cannot be used."),(0,i.kt)("h2",{id:"devices-with-end-to-end-support"},"Devices with End-to-End Support"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"GPU",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"NVIDIA GPU"),(0,i.kt)("li",{parentName:"ul"},"Huawei Ascend NPU"),(0,i.kt)("li",{parentName:"ul"},"Cambricon MLU"))),(0,i.kt)("li",{parentName:"ul"},"RDMA",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Generic, vendor-agnostic")))),(0,i.kt)("h2",{id:"whats-next"},"What\u2019s Next"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Learn ",(0,i.kt)("a",{parentName:"li",href:"/docs/next/user-manuals/fine-grained-device-scheduling"},"how to use fine-grained device scheduling"),".")))}h.isMDXComponent=!0},9062:(e,n,t)=>{t.d(n,{Z:()=>o});const o=t.p+"assets/images/device-scheduling-architecture-f6dc2e74f676861e32a7224182d2fbfe.jpg"}}]);