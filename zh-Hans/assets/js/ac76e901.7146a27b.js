"use strict";(self.webpackChunkkoordinator_sh=self.webpackChunkkoordinator_sh||[]).push([[3689],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>k});var a=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},d=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),c=p(t),u=o,k=c["".concat(s,".").concat(u)]||c[u]||m[u]||r;return t?a.createElement(k,l(l({ref:n},d),{},{components:t})):a.createElement(k,l({ref:n},d))}));function k(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=t.length,l=new Array(r);l[0]=u;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i[c]="string"==typeof e?e:o,l[1]=i;for(var p=2;p<r;p++)l[p]=t[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},501:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>p});var a=t(7462),o=(t(7294),t(3905));const r={},l="GPU & RDMA Joint Allocation",i={unversionedId:"user-manuals/gpu-and-rdma-joint-allocation",id:"user-manuals/gpu-and-rdma-joint-allocation",title:"GPU & RDMA Joint Allocation",description:"Introduction",source:"@site/i18n/zh-Hans/docusaurus-plugin-content-docs/current/user-manuals/gpu-and-rdma-joint-allocation.md",sourceDirName:"user-manuals",slug:"/user-manuals/gpu-and-rdma-joint-allocation",permalink:"/zh-Hans/docs/next/user-manuals/gpu-and-rdma-joint-allocation",draft:!1,editUrl:"https://github.com/koordinator-sh/koordinator.sh/edit/main/docs/user-manuals/gpu-and-rdma-joint-allocation.md",tags:[],version:"current",lastUpdatedBy:"\u4e54\u666e",lastUpdatedAt:1760432653,formattedLastUpdatedAt:"2025\u5e7410\u670814\u65e5",frontMatter:{},sidebar:"docs",previous:{title:"Device Scheduling - GPU Share With HAMi",permalink:"/zh-Hans/docs/next/user-manuals/device-scheduling-gpu-share-with-hami"},next:{title:"\u8bbe\u5907\u8c03\u5ea6 - \u534e\u4e3a\u6607\u817e NPU",permalink:"/zh-Hans/docs/next/user-manuals/device-scheduling-ascend-npu"}},s={},p=[{value:"Introduction",id:"introduction",level:2},{value:"Prerequisite",id:"prerequisite",level:2},{value:"Environment Setting",id:"environment-setting",level:2},{value:"Cluster And Nodes",id:"cluster-and-nodes",level:3},{value:"Details about GPUs And NICs",id:"details-about-gpus-and-nics",level:3},{value:"Deploy Koordinator, Multus-CNI and SRIOV-CNI",id:"deploy-koordinator-multus-cni-and-sriov-cni",level:2},{value:"Deploy Koordinator",id:"deploy-koordinator",level:3},{value:"Deploy Multus",id:"deploy-multus",level:3},{value:"Plan NAD for Nodes",id:"plan-nad-for-nodes",level:3},{value:"Deploy SRIOV-CNI",id:"deploy-sriov-cni",level:3},{value:"Deploy Pods and Check Allocation Result",id:"deploy-pods-and-check-allocation-result",level:2},{value:"Deploy Application Pods",id:"deploy-application-pods",level:3},{value:"Check Device Allocation Result",id:"check-device-allocation-result",level:3},{value:"Check RDMA Connectivity",id:"check-rdma-connectivity",level:2},{value:"Check Network Connectivity",id:"check-network-connectivity",level:3},{value:"Check RDMA Connectivity",id:"check-rdma-connectivity-1",level:3},{value:"Check GPUDirect RDMA",id:"check-gpudirect-rdma",level:2},{value:"Install the NCCL Library and Compile",id:"install-the-nccl-library-and-compile",level:3},{value:"Setup Mutual Trust between Pods",id:"setup-mutual-trust-between-pods",level:3},{value:"Install openssh",id:"install-openssh",level:4},{value:"Generate RSA Key",id:"generate-rsa-key",level:4},{value:"Start sshd",id:"start-sshd",level:4},{value:"Verify SSH Connectivity",id:"verify-ssh-connectivity",level:4},{value:"Double Machine IB Communication",id:"double-machine-ib-communication",level:3}],d={toc:p},c="wrapper";function m(e){let{components:n,...r}=e;return(0,o.kt)(c,(0,a.Z)({},d,r,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"gpu--rdma-joint-allocation"},"GPU & RDMA Joint Allocation"),(0,o.kt)("h2",{id:"introduction"},"Introduction"),(0,o.kt)("p",null,"In the AI model training scenario, collective communication between GPUs is involved, which may occur across nodes. To improve network communication speed, NICs that support the RDMA protocol are widely used in AI training scenarios."),(0,o.kt)("p",null,"Since v1.5.0, Koordinator has implemented joint scheduling capabilities for GPU and RDMA. In version v1.6.0, Koordinator provides an end-to-end solution for this. The overall architecture is as follows:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"image",src:t(5050).Z,width:"3348",height:"1671"})),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Koordlet detects the GPUs and RDMA-capable NICs in nodes and reports related information to the Device CR.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Koord-Manager syncs resources from the Device CR to node.status.allocatable.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Koord-Scheduler allocates GPUs and RDMA-capable NICs for pods according to device topology and annotates the pods with the allocation results.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Multus-CNI accesses the Koordlet PodResources Proxy to obtain the RDMA devices allocated to the pod and attaches the corresponding NICs to the pod's network namespace.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Koordlet provides NRI plugins that can mount devices into containers."))),(0,o.kt)("p",null,"Due to the numerous components involved and the complexity of the environment, we provide this best practice guide. In this guide, we will demonstrate how to deploy Koordinator, Multus-CNI, and SRIOV-CNI step by step, as well as how to use NCCL programs to confirm that our system is indeed working. "),(0,o.kt)("p",null,"The basic validation logic is as follows: "),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"the user will submit two Pods requesting GPU and RDMA resources, respectively. "),(0,o.kt)("li",{parentName:"ol"},"Koordinator will allocate these two Pods to designated nodes, ensuring that the GPUs and RDMA assigned to the Pods are located under the same PCIe switch. "),(0,o.kt)("li",{parentName:"ol"},"We will then verify the RDMA connectivity between the Pods and ultimately use MPI to validate that GDR can run successfully.")),(0,o.kt)("p",null,"Finally, from the data plane perspective, the device topology possessed by the Pods and the network association between the Pods appear as follows:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"image",src:t(140).Z,width:"2060",height:"966"})),(0,o.kt)("h2",{id:"prerequisite"},"Prerequisite"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Kuberenetes >= 1.28"),(0,o.kt)("li",{parentName:"ul"},"Koordinator >= 1.6"),(0,o.kt)("li",{parentName:"ul"},"Containerd >= 1.7"),(0,o.kt)("li",{parentName:"ul"},"Multus-CNI >= 4.0"),(0,o.kt)("li",{parentName:"ul"},"SRIOV-CNI >= 2.0")),(0,o.kt)("h2",{id:"environment-setting"},"Environment Setting"),(0,o.kt)("h3",{id:"cluster-and-nodes"},"Cluster And Nodes"),(0,o.kt)("p",null,"Our cluster has two worker nodes and one master node. The details version info is as follwoing table."),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Node Name"),(0,o.kt)("th",{parentName:"tr",align:null},"Kuberntes Version"),(0,o.kt)("th",{parentName:"tr",align:null},"IP"),(0,o.kt)("th",{parentName:"tr",align:null},"OS"),(0,o.kt)("th",{parentName:"tr",align:null},"Kernel"),(0,o.kt)("th",{parentName:"tr",align:null},"GPU"),(0,o.kt)("th",{parentName:"tr",align:null},"GPU Driver Version"),(0,o.kt)("th",{parentName:"tr",align:null},"Cuda"),(0,o.kt)("th",{parentName:"tr",align:null},"Containerd"),(0,o.kt)("th",{parentName:"tr",align:null},"nvidia-container-runtime"),(0,o.kt)("th",{parentName:"tr",align:null},"NIC"),(0,o.kt)("th",{parentName:"tr",align:null},"NIC Driver Version"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"k8s-master"),(0,o.kt)("td",{parentName:"tr",align:null},"v1.28.15"),(0,o.kt)("td",{parentName:"tr",align:null},"192.168.10.203"),(0,o.kt)("td",{parentName:"tr",align:null},"Ubuntu 22.04.4 LTS"),(0,o.kt)("td",{parentName:"tr",align:null},"6.8.0-45-generic"),(0,o.kt)("td",{parentName:"tr",align:null},"/"),(0,o.kt)("td",{parentName:"tr",align:null},"/"),(0,o.kt)("td",{parentName:"tr",align:null},"/"),(0,o.kt)("td",{parentName:"tr",align:null},"containerd://1.7.22"),(0,o.kt)("td",{parentName:"tr",align:null},"/"),(0,o.kt)("td",{parentName:"tr",align:null},"/"),(0,o.kt)("td",{parentName:"tr",align:null},"/")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"k8s-node1"),(0,o.kt)("td",{parentName:"tr",align:null},"v1.28.15"),(0,o.kt)("td",{parentName:"tr",align:null},"192.168.10.232"),(0,o.kt)("td",{parentName:"tr",align:null},"Ubuntu 22.04.4 LTS"),(0,o.kt)("td",{parentName:"tr",align:null},"6.8.0-45-generic"),(0,o.kt)("td",{parentName:"tr",align:null},"P40*4"),(0,o.kt)("td",{parentName:"tr",align:null},"550.127.05"),(0,o.kt)("td",{parentName:"tr",align:null},"12.4"),(0,o.kt)("td",{parentName:"tr",align:null},"containerd://1.7.22"),(0,o.kt)("td",{parentName:"tr",align:null},"3.14.0-1"),(0,o.kt)("td",{parentName:"tr",align:null},"Mellanox Technologies MT27800 Family ","[ConnectX-5]"),(0,o.kt)("td",{parentName:"tr",align:null},"MLNX_OFED_LINUX-24.07-0.6.1.0")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"k8s-node2"),(0,o.kt)("td",{parentName:"tr",align:null},"v1.28.15"),(0,o.kt)("td",{parentName:"tr",align:null},"192.168.10.231"),(0,o.kt)("td",{parentName:"tr",align:null},"Ubuntu 22.04.4 LTS"),(0,o.kt)("td",{parentName:"tr",align:null},"6.8.0-45-generic"),(0,o.kt)("td",{parentName:"tr",align:null},"P40*4"),(0,o.kt)("td",{parentName:"tr",align:null},"550.127.05"),(0,o.kt)("td",{parentName:"tr",align:null},"12.4"),(0,o.kt)("td",{parentName:"tr",align:null},"containerd://1.7.22"),(0,o.kt)("td",{parentName:"tr",align:null},"3.14.0-1"),(0,o.kt)("td",{parentName:"tr",align:null},"Mellanox Technologies MT27800 Family ","[ConnectX-5]"),(0,o.kt)("td",{parentName:"tr",align:null},"Driver version\uff1aMLNX_OFED_LINUX-24.07-0.6.1.0")))),(0,o.kt)("p",null,"The device information and network connectivity information for the two worker nodes are pictured as follows:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"image",src:t(5309).Z,width:"920",height:"415"})),(0,o.kt)("h3",{id:"details-about-gpus-and-nics"},"Details about GPUs And NICs"),(0,o.kt)("p",null,"Every worker has 4 Tesla P40 GPUs."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@k8s-node1:~/ss/koo/script# nvidia-smi\nWed Nov 27 16:21:46 2024\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P40                      Off |   00000000:02:00.0 Off |                    0 |\n| N/A   21C    P8             12W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla P40                      Off |   00000000:03:00.0 Off |                    0 |\n| N/A   26C    P8             10W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   2  Tesla P40                      Off |   00000000:82:00.0 Off |                    0 |\n| N/A   23C    P8             10W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   3  Tesla P40                      Off |   00000000:83:00.0 Off |                    0 |\n| N/A   18C    P8              8W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@k8s-node2:~# nvidia-smi\nWed Nov 27 16:22:16 2024\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P40                      Off |   00000000:02:00.0 Off |                    0 |\n| N/A   31C    P8             10W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla P40                      Off |   00000000:03:00.0 Off |                    0 |\n| N/A   31C    P8             10W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   2  Tesla P40                      Off |   00000000:82:00.0 Off |                    0 |\n| N/A   37C    P8             10W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   3  Tesla P40                      Off |   00000000:83:00.0 Off |                    0 |\n| N/A   30C    P8             10W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n")),(0,o.kt)("p",null,"In addition to GPU, we also need to setup rdma environment on the worker nodes in advance."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Plan the physical NIC for the test"),(0,o.kt)("table",{parentName:"li"},(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"node name"),(0,o.kt)("th",{parentName:"tr",align:null},"nic name"),(0,o.kt)("th",{parentName:"tr",align:null},"Nic model"),(0,o.kt)("th",{parentName:"tr",align:null},"NAD name"),(0,o.kt)("th",{parentName:"tr",align:null},"Ip address"),(0,o.kt)("th",{parentName:"tr",align:null},"remark"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"K8s-node1"),(0,o.kt)("td",{parentName:"tr",align:null},"ens11f0np0",(0,o.kt)("br",null),"ens11f1np1"),(0,o.kt)("td",{parentName:"tr",align:null},"01:00.0 Ethernet controller ","[0200]",": Mellanox Technologies MT27800 Family ","[ConnectX-5][15b3:1017]",(0,o.kt)("br",null),"01:00.1 Ethernet controller ","[0200]",": Mellanox Technologies MT27800 Family ","[ConnectX-5][15b3:1017]"),(0,o.kt)("td",{parentName:"tr",align:null},"sriov-attach-k8s-node1-ens11f0np0-kubeflow-conf"),(0,o.kt)("td",{parentName:"tr",align:null},"10.20.12.121"),(0,o.kt)("td",{parentName:"tr",align:null},"To simplify the testing, we create pod01 and have it schedule directionally to node1 and occupy the VF on node1")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"K8s-node2"),(0,o.kt)("td",{parentName:"tr",align:null},"ens3f0np0",(0,o.kt)("br",null),"ens3f1np1"),(0,o.kt)("td",{parentName:"tr",align:null},"81:00.0 Ethernet controller ","[0200]",": Mellanox Technologies MT27800 Family ","[ConnectX-5][15b3:1017]",(0,o.kt)("br",null),"81:00.1 Ethernet controller ","[0200]",": Mellanox Technologies MT27800 Family ","[ConnectX-5][15b3:1017]"),(0,o.kt)("td",{parentName:"tr",align:null},"sriov-attach-k8s-node2-ens3f0np0-kubeflow-conf"),(0,o.kt)("td",{parentName:"tr",align:null},"10.20.12.134"),(0,o.kt)("td",{parentName:"tr",align:null},"To simplify the testing, we create pod02 and have it schedule directionally to node2 and occupy this VF"))))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a VF on node1"),(0,o.kt)("p",{parentName:"li"},"Log in to node1 and create VF based on the Mellanox CX5 network adapter. Since the host already has two nics, three cx5 nics will appear if VF is successfully created."),(0,o.kt)("p",{parentName:"li"},"Create instruction is as follows:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"echo '1' > /sys/class/net/ens11f0np0/device/sriov_numvfs\n")),(0,o.kt)("p",{parentName:"li"},'The host runs the following command: "lspci |grep Mell". If ',"[ConnectX-5 Virtual Function]"," is displayed, VF is created successfully."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@k8s-node1:/data/cc/code/koordinator# lspci |grep Mell\n01:00.0 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\n01:00.1 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\n01:00.2 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5 Virtual Function] //VF\n")),(0,o.kt)("p",{parentName:"li"},"If you run ibstat, mlx5_2 in the output is VF\uff1a"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"CA 'mlx5_0'\n        CA type: MT4119\n        Number of ports: 1\n        Firmware version: 16.35.4030\n        Hardware version: 0\n        Node GUID: 0x1070fd0300a4487a\n        System image GUID: 0x1070fd0300a4487a\n        Port 1:\n                State: Active\n                Physical state: LinkUp\n                Rate: 25\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x1270fdfffea4487a\n                Link layer: Ethernet\nCA 'mlx5_1'\n        CA type: MT4119\n        Number of ports: 1\n        Firmware version: 16.35.4030\n        Hardware version: 0\n        Node GUID: 0x1070fd0300a4487b\n        System image GUID: 0x1070fd0300a4487a\n        Port 1:\n                State: Down\n                Physical state: Disabled\n                Rate: 25\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x1270fdfffea4487b\n                Link layer: Ethernet\nCA 'mlx5_2'      //VF\n        CA type: MT4120\n        Number of ports: 1\n        Firmware version: 16.35.4030\n        Hardware version: 0\n        Node GUID: 0x0000000000000000\n        System image GUID: 0x1070fd0300a4487a\n        Port 1:\n                State: Active\n                Physical state: LinkUp\n                Rate: 25\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x0000000000000000\n                Link layer: Ethernet\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a VF on node2"),(0,o.kt)("p",{parentName:"li"},"Log in to node2 and create VF based on the Mellanox CX5 network adapter. The host already has two cx5 nics. If the VF is created successfully, three cx5 nics are displayed."),(0,o.kt)("p",{parentName:"li"},"Create instruction is as follows:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"echo '1' > / sys/class/net/ens11f0np0 / device/sriov_numvfs\n")),(0,o.kt)("p",{parentName:"li"},'The host runs the following command: "lspci |grep Mell". If ',"[ConnectX-5 Virtual Function]"," is displayed, VF is created successfully."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@k8s-node3:~# lspci |grep Mell\nd2:00.0 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\nd2:00.1 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5]\nd2:01.2 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5 Virtual Function]//VF\n")),(0,o.kt)("p",{parentName:"li"},"If you run ibstat, mlx5_2 in the output is VF"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"CA 'mlx5_0'\n        CA type: MT4119\n        Number of ports: 1\n        Firmware version: 16.32.1010\n        Hardware version: 0\n        Node GUID: 0x1070fd0300a4486a\n        System image GUID: 0x1070fd0300a4486a\n        Port 1:\n                State: Down\n                Physical state: Disabled\n                Rate: 40\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x0000000000000000\n                Link layer: Ethernet\nCA 'mlx5_1'\n        CA type: MT4119\n        Number of ports: 1\n        Firmware version: 16.32.1010\n        Hardware version: 0\n        Node GUID: 0x1070fd0300a4486b\n        System image GUID: 0x1070fd0300a4486a\n        Port 1:\n                State: Down\n                Physical state: Disabled\n                Rate: 25\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x0000000000000000\n                Link layer: Ethernet\nCA 'mlx5_2'               //VF\n        CA type: MT4119\n        Number of ports: 1\n        Firmware version: 16.35.3006\n        Hardware version: 0\n        Node GUID: 0x1070fd0300a44882\n        System image GUID: 0x1070fd0300a44882\n        Port 1:\n                State: Down\n                Physical state: Disabled\n                Rate: 40\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x0000000000000000\n                Link layer: Ethernet\n")))),(0,o.kt)("h2",{id:"deploy-koordinator-multus-cni-and-sriov-cni"},"Deploy Koordinator, Multus-CNI and SRIOV-CNI"),(0,o.kt)("h3",{id:"deploy-koordinator"},"Deploy Koordinator"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\nhelm repo update\nhelm install koordinator koordinator-sh/koordinator --version 1.6.0\n")),(0,o.kt)("p",null,"The modified yaml feature parameters of koordlet componet are as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"- -feature-gates=Accelerators=true,GPUEnvInject=true,RDMADeviceInject=true,RDMADevices=true,PodResourcesProxy=true\n")),(0,o.kt)("h3",{id:"deploy-multus"},"Deploy Multus"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"To use latest features try command below which applies a daemonset and installs thick Multus using kubectl:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -f https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/deployments/multus-daemonset-thick.yml\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@k8s-master:~# kubectl get po -n kube-system |grep multus\nkube-multus-ds-7ddbh                   1/1     Running   0          38h\nkube-multus-ds-cgvqq                   1/1     Running   0          38h\nkube-multus-ds-lc6nv                   1/1     Running   0          38h\n")),(0,o.kt)("p",{parentName:"li"},"This indicates that your systems is ready to use Multus CNI. Supported from Multus-CNI release 4.0+.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Modify the daemonset to adapt to koordinator"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl edit ds kube-multus-ds -n kube-system \n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-multus-ds\n  namespace: kube-system\n  labels:\n    tier: node\n    app: multus\n    name: multus\nspec:\n  selector:\n    matchLabels:\n      name: multus\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        tier: node\n        app: multus\n        name: multus\n    spec:\n      containers:\n        - name: kube-multus\n          volumeMounts:\n            ...\n            - name: host-var-lib-kubelet\n              mountPath: /var/lib/kubelet/pod-resources\n              mountPropagation: HostToContainer\n            ...\n      volumes:\n        ...\n        - name: host-var-lib-kubelet\n          hostPath:\n            path: /var/run/koordlet/pod-resources\n        ...\n")))),(0,o.kt)("h3",{id:"plan-nad-for-nodes"},"Plan NAD for Nodes"),(0,o.kt)("p",null,"Multus CNI relys on NetworkAttachmentDefinition configuration to allocate ip and configure network, we as cluster admin need to plan NAD configuration file in advance."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"the NAD of ens11f0np0 on node1 is as following:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: "k8s.cni.cncf.io/v1"\nkind: NetworkAttachmentDefinition\nmetadata:\n  name: sriov-attach-k8s-node1-ens11f0np0-kubeflow-conf\n  namespace: kubeflow\n  annotations:\n    k8s.v1.cni.cncf.io/resourceName: koordinator.sh/rdma\nspec:\n  config: \'{\n  "cniVersion": "0.3.1",\n  "name": "sriov-attach",\n  "type": "sriov",\n  "capabilities": {\n     "mac": true,\n     "ipam": true\n  },\n  "master": "ens11f0np0",\n  "mode": "passthrough",\n  "ipam": {\n    "type": "host-local",\n    "subnet": "10.20.12.0/24",\n    "rangeStart": "10.20.12.121", //Plan the IP address range of the Pod\n    "rangeEnd": "10.20.12.121"\n  }\n}\'\n')),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},"the NAD of ens3f0np0 on node2 is as following:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'  apiVersion: "k8s.cni.cncf.io/v1"\n  kind: NetworkAttachmentDefinition\n  metadata:\n    name: sriov-attach-k8s-node2-ens3f0np0-kubeflow-conf\n    namespace: kubeflow\n    annotations:\n      k8s.v1.cni.cncf.io/resourceName: koordinator.sh/rdma\n  spec:\n    config: \'{\n    "cniVersion": "0.3.1",\n    "name": "sriov-attach",\n    "type": "sriov",\n    "capabilities": {\n       "mac": true,\n       "ipam": true\n    },\n    "master": "ens3f0np0",\n    "mode": "passthrough",\n    "ipam": {\n      "type": "host-local",\n      "subnet": "10.20.12.0/24",\n      "rangeStart": "10.20.12.134",//Plan the IP address range of the Pod\n      "rangeEnd": "10.20.12.134"\n    }\n  }\'\n')),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"create Namespace on k8s cluster"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"kubectl create ns kubeflow\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Run the following command to deploy the nad"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -f sriov-attach-k8s-node1-ens11f0np0-kubeflow-conf.yaml\nkubectl apply -f sriov-attach-k8s-node2-ens3f0np0-kubeflow-conf.yaml\n")))),(0,o.kt)("h3",{id:"deploy-sriov-cni"},"Deploy SRIOV-CNI"),(0,o.kt)("p",null,"See the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/k8snetworkplumbingwg/sriov-cni"},"SR-IOV CNI")," repository for build and installation instructions. Supported from SR-IOV CNI release 2.0+."),(0,o.kt)("h2",{id:"deploy-pods-and-check-allocation-result"},"Deploy Pods and Check Allocation Result"),(0,o.kt)("h3",{id:"deploy-application-pods"},"Deploy Application Pods"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Note: This experiment requires two pods, so you need to write yaml files corresponding to two Pods. Expect one Pod directed to node1 and one Pod directed to node2.")),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Label Nodes: In order to facilitate testing, Pod directional scheduling is required to a node, and Node needs to be labeled. Specific instructions are as follows"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl label nodes k8s-node1 koo=node1\nkubectl label nodes k8s-node2 koo=node2\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Deploy Pods: Run the following command to deploy the Pod"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -f pod01.yaml\nkubectl apply -f pod02.yaml\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-vf01\n  namespace: kubeflow\n  annotations:\n    # this NAD is already written previously\n    k8s.v1.cni.cncf.io/networks: sriov-attach-k8s-node1-ens11f0np0-kubeflow-conf\n    scheduling.koordinator.sh/device-joint-allocate: |-\n      {\n        "deviceTypes": ["gpu","rdma"]\n      }\n    scheduling.koordinator.sh/device-allocate-hint: |-\n      {\n       "rdma": {\n         "vfSelector": {} //apply VF\n       }\n      }\n  labels:\n    selector-type: pod\nspec:\n  nodeSelector:\n    koo: node1     //Directional scheduling to 1 node\n  schedulerName: koord-scheduler //Uses the koordlet scheduling plug-in\n  containers:\n  - name: container-vf\n    image: nvcr.io/nvidia/pytorch:24.04-py3\n    securityContext:\n      capabilities:\n        add: [ "IPC_LOCK" ]\n    imagePullPolicy: IfNotPresent\n    command: [ "/bin/bash", "-c", "--" ]\n    args: [ "while true; do sleep 300000; done;" ]\n    volumeMounts:\n    - mountPath: /dev/shm\n      name: shm\n    resources:\n      requests:\n        koordinator.sh/gpu: 100//apply a GPU\n        koordinator.sh/rdma: 100//apply a VF\n      limits:\n        koordinator.sh/gpu: 100\n        koordinator.sh/rdma: 100\n  volumes:\n  - name: shm\n    emptyDir:\n      medium: Memory\n      sizeLimit: "10Gi"\n')),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-vf02\n  namespace: kubeflow\n  annotations:\n    k8s.v1.cni.cncf.io/networks: sriov-attach-k8s-node3-enp210s0f1np1-kubeflow-conf\n    scheduling.koordinator.sh/device-joint-allocate: |-\n      {\n        "deviceTypes": ["gpu","rdma"]\n      }\n    scheduling.koordinator.sh/device-allocate-hint: |-\n      {\n       "rdma": {\n         "vfSelector": {}\n       }\n      }\n  labels:\n    selector-type: pod\nspec:\n  nodeSelector:\n    koo: node2\n  schedulerName: koord-scheduler\n  containers:\n  - name: container-vf\n    image: nvcr.io/nvidia/pytorch:24.04-py3\n    securityContext:\n      capabilities:\n        add: [ "IPC_LOCK" ]\n    imagePullPolicy: IfNotPresent\n    command: [ "/bin/bash", "-c", "--" ]\n    args: [ "while true; do sleep 300000; done;" ]\n    volumeMounts:\n    - mountPath: /dev/shm\n      name: shm\n    resources:\n      requests:\n        koordinator.sh/gpu: 100\n        koordinator.sh/rdma: 100\n      limits:\n        koordinator.sh/gpu: 100\n        koordinator.sh/rdma: 100\n  volumes:\n  - name: shm\n    emptyDir:\n      medium: Memory\n      sizeLimit: "10Gi"\n'))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Check pod running status"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@k8s-master:~/ss/koo/rdma/sriov# kubectl get po -n kubeflow -owide\nNAME       READY   STATUS    RESTARTS   AGE    IP            NODE        NOMINATED NODE   READINESS GATES\npod-vf01   1/1     Running   0          103m   10.244.1.10   k8s-node1   <none>           <none>\npod-vf02   1/1     Running   0          10h    10.244.2.18   k8s-node2   <none>           <none>\n")),(0,o.kt)("p",{parentName:"li"},"If the status of the pod is running, the pod is successfully created and running."))),(0,o.kt)("h3",{id:"check-device-allocation-result"},"Check Device Allocation Result"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"We extract the allocation information of pod-vf01 through the following command"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl get pod pod-vf01 -n kubeflow -oyaml\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'scheduling.koordinator.sh/device-allocated: \'{"gpu":[{"minor":0,"resources":{"koordinator.sh/gpu-core":"100","koordinator.sh/gpu-memory":"23040Mi","koordinator.sh/gpu-memory-ratio":"100"}}],"rdma":[{"minor":0,"resources":{"koordinator.sh/rdma":"1"},"extension":{"vfs":[{"minor":-1,"busID":"0000:01:00.2"}]}}]}\'\n ......\n dnsPolicy: ClusterFirst\n  enableServiceLinks: true\n  nodeName: k8s-node1         //It has been scheduled to node 1\n  nodeSelector:\n    koo: node1\n  preemptionPolicy: PreemptLowerPriority\n  priority: 0\n  restartPolicy: Always\n  schedulerName: koord-scheduler\n'))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},'Enter the container and run the command "nvidia-smi" and Check the GPU allocation result'),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@pod-vf01:/home# nvidia-smi\nFri Nov 22 06:55:59 2024\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P40                      Off |   00000000:02:00.0 Off |                    0 |\n| N/A   24C    P8             10W /  250W |       0MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n")))),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Check whether the Pod named pod-vf01 device assignment results meet affinity"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl get devices.scheduling.koordinator.sh k8s-node1 -oyaml\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.koordinator.sh/v1alpha1\nkind: Device\nmetadata:\n  .....\nspec:\n  devices:\n  - health: true\n    id: GPU-989aa251-1dfe-5bbc-7c12-46e817b1de9a\n    minor: 0    //The GPU to which pod-vf01 is assigned is GPU 0, and the corresponding PCIE is pci0000:00\n    resources:\n      koordinator.sh/gpu-core: "100"\n      koordinator.sh/gpu-memory: 23040Mi\n      koordinator.sh/gpu-memory-ratio: "100"\n    topology:\n      busID: "0000:02:00.0"\n      nodeID: 0\n      pcieID: pci0000:00\n      socketID: -1\n    type: gpu\n  - health: true\n    id: "0000:01:00.0"\n    minor: 0\n    resources:\n      koordinator.sh/rdma: "100"\n    topology:\n      busID: "0000:01:00.0"\n      nodeID: 0\n      pcieID: pci0000:00\n      socketID: -1\n    type: rdma\n    vfGroups:\n    - vfs:\n      - busID: "0000:01:00.2"//pod-vf01 is assigned to this vf device, and the corresponding PCIE is pci0000:00\n        minor: -1\n  - health: true\n    id: GPU-e8a40bd0-e484-2d1b-cad9-75b043139b0c\n    minor: 1\n    resources:\n      koordinator.sh/gpu-core: "100"\n      koordinator.sh/gpu-memory: 23040Mi\n      koordinator.sh/gpu-memory-ratio: "100"\n    topology:\n      busID: "0000:03:00.0"\n      nodeID: 0\n      pcieID: pci0000:00\n      socketID: -1\n    type: gpu\n  - health: true\n    id: "0000:01:00.1"\n    minor: 1\n    resources:\n      koordinator.sh/rdma: "100"\n    topology:\n      busID: "0000:01:00.1"\n      nodeID: 0\n      pcieID: pci0000:00\n      socketID: -1\n    type: rdma\n  - health: true\n    id: GPU-5293b3a7-2bbb-e135-c6ab-c548b5c5b0a6\n    minor: 2\n    resources:\n      koordinator.sh/gpu-core: "100"\n      koordinator.sh/gpu-memory: 23040Mi\n      koordinator.sh/gpu-memory-ratio: "100"\n    topology:\n      busID: 0000:82:00.0\n      nodeID: 0\n      pcieID: pci0000:80\n      socketID: -1\n    type: gpu\n  - health: true\n    id: "0000:05:00.0"\n    minor: 2\n    resources:\n      koordinator.sh/rdma: "100"\n    topology:\n      busID: "0000:05:00.0"\n      nodeID: 0\n      pcieID: pci0000:00\n      socketID: -1\n    type: rdma\n  - health: true\n    id: GPU-d60a283a-a846-eaa7-f551-c0c4f6f4402a\n    minor: 3\n    resources:\n      koordinator.sh/gpu-core: "100"\n      koordinator.sh/gpu-memory: 23040Mi\n      koordinator.sh/gpu-memory-ratio: "100"\n    topology:\n      busID: 0000:83:00.0\n      nodeID: 0\n      pcieID: pci0000:80\n      socketID: -1\n    type: gpu\nstatus: {}\n')),(0,o.kt)("p",{parentName:"li"},'According to the topology information, pod-vf01 is assigned to the vf device busID: "0000:01:00.2", and the corresponding PCIE is pci0000:00. The GPU to which pod-vf01 is assigned is GPU 0, and the corresponding PCIE is pci0000:00. Because PCIE is the same, the GPU and NIC meet the expected topology affinity.')),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"In the same way, check whether the device assignment result of pod-vf02 meets affinity"))),(0,o.kt)("p",null,"At this point, one GPU and one RDMA device applied by the two Pods are successfully allocated, and the topology affinity is met."),(0,o.kt)("h2",{id:"check-rdma-connectivity"},"Check RDMA Connectivity"),(0,o.kt)("h3",{id:"check-network-connectivity"},"Check Network Connectivity"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter the pod and install basic network tools"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl exec -it pod-vf01 -n kubeflow -- bash\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"apt-get update\napt-get install -y net-tools\napt install -y iputils-ping\napt-get install infiniband-diags -y\napt-get install -y kmod\napt-get install -y perftest\napt-get install -y  ethtool\n......\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Check the IP address assignment."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.244.1.10  netmask 255.255.255.0  broadcast 10.244.1.255\n        inet6 fe80::e4c7:a3ff:fe4c:9d15  prefixlen 64  scopeid 0x20<link>\n        ether e6:c7:a3:4c:9d:15  txqueuelen 0  (Ethernet)\n        RX packets 17129  bytes 57434980 (57.4 MB)\n        RX errors 0  dropped 244  overruns 0  frame 0\n        TX packets 13383  bytes 1019323 (1.0 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 487  bytes 211446 (211.4 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 487  bytes 211446 (211.4 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nnet1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.20.12.121  netmask 255.255.255.0  broadcast 10.20.12.255\n        inet6 fe80::6ce7:bfff:fee0:9382  prefixlen 64  scopeid 0x20<link>\n        ether 6e:e7:bf:e0:93:82  txqueuelen 1000  (Ethernet)\n        RX packets 477  bytes 86270 (86.2 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 327  bytes 47335 (47.3 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n")),(0,o.kt)("p",{parentName:"li"},"The net1 network port name here is the network port name assigned by multus-cni to pod, and the address is the address segment we configured in the previous nad named sriov-attach-k8s-node1-ens11f0np0-kubeflow-conf: 10.20.12.121.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Same as pod-vf01, the IP address of pod-vf02 is as following:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.244.2.21  netmask 255.255.255.0  broadcast 10.244.2.255\n        inet6 fe80::f45c:90ff:fe3a:67a2  prefixlen 64  scopeid 0x20<link>\n        ether f6:5c:90:3a:67:a2  txqueuelen 0  (Ethernet)\n        RX packets 21690  bytes 65555332 (65.5 MB)\n        RX errors 0  dropped 1310  overruns 0  frame 0\n        TX packets 15612  bytes 1218973 (1.2 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 794  bytes 277124 (277.1 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 794  bytes 277124 (277.1 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nnet1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.20.12.134  netmask 255.255.255.0  broadcast 10.20.12.255\n        inet6 fe80::ac97:a4ff:fe72:d1f1  prefixlen 64  scopeid 0x20<link>\n        ether ae:97:a4:72:d1:f1  txqueuelen 1000  (Ethernet)\n        RX packets 492  bytes 110501 (110.5 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 318  bytes 42371 (42.3 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n")),(0,o.kt)("p",{parentName:"li"},"The net1 network port name here is the network port name assigned by multus-cni to pod, and the address is the address segment we configured in the previous nad named sriov-attach-k8s-node2-ens3f0np0-kubeflow-conf: 10.20.12.134.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Ping pod-vf02's net1 network port inside pod-vf01:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@pod-vf01:/workspace# ping 10.20.12.134\nPING 10.20.12.134 (10.20.12.134) 56(84) bytes of data.\n64 bytes from 10.20.12.134: icmp_seq=1 ttl=64 time=0.293 ms\n64 bytes from 10.20.12.134: icmp_seq=2 ttl=64 time=0.212 ms\n64 bytes from 10.20.12.134: icmp_seq=3 ttl=64 time=0.216 ms\n64 bytes from 10.20.12.134: icmp_seq=4 ttl=64 time=0.221 ms\n")),(0,o.kt)("p",{parentName:"li"},"The results show that the two Pods can communicate with each other, but ping is not enough to prove that the VF ports assigned by the two cx5 can communicate. You need to perform further tests on the specified vf port."))),(0,o.kt)("h3",{id:"check-rdma-connectivity-1"},"Check RDMA Connectivity"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Check the mounting information of vf devices inside the pod, using POD-VF01 as an example (pod-vf02 refer to pod-vf01 for the same reason, no special explanation is provided here)."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"root@pod-vf01:/workspace# ibstat\nCA 'mlx5_0'\n        CA type: MT4119\n        Number of ports: 1\n        Firmware version: 16.35.4030\n        Hardware version: 0\n        Node GUID: 0x1070fd0300a4487a\n        System image GUID: 0x1070fd0300a4487a\n        Port 1:\n                State: Active\n                Physical state: LinkUp\n                Rate: 25\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x0000000000000000\n                Link layer: Ethernet\nCA 'mlx5_1'\n        CA type: MT4119\n        Number of ports: 1\n        Firmware version: 16.35.4030\n        Hardware version: 0\n        Node GUID: 0x1070fd0300a4487b\n        System image GUID: 0x1070fd0300a4487a\n        Port 1:\n                State: Down\n                Physical state: Disabled\n                Rate: 25\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x0000000000000000\n                Link layer: Ethernet\nCA 'mlx5_2'//VF\n        CA type: MT4120\n        Number of ports: 1\n        Firmware version: 16.35.4030\n        Hardware version: 0\n        Node GUID: 0x0000000000000000\n        System image GUID: 0x1070fd0300a4487a\n        Port 1:\n                State: Active\n                Physical state: LinkUp\n                Rate: 25\n                Base lid: 0\n                LMC: 0\n                SM lid: 0\n                Capability mask: 0x00010000\n                Port GUID: 0x6ce7bffffee09382\n                Link layer: Ethernet\n")),(0,o.kt)("p",{parentName:"li"},"You can see three network ports: mlx5_0 (Up), mlx5_1 (Down), and mlx5_2 (Up). In fact, the VF we apply for comes from the mlx5_2 virtualized by the physical network adapter mlx5_0. That is, mlx5_2 is a virtual network interface, which is derived from mlx5_0. mlx5_1 is unavailable in the Down state. The pod should actually only use the mlx5_2 virtual VF communication inside. Similarly, the VF port used by pod-vf02 is mlx5_2. So let's do a test.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter the Pod-vf01 container, use the mlx5_2 (VF) port to enable the ib_write listening service."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@pod-vf01:/workspace# ib_write_bw -d mlx5_2 -F\n\n************************************\nWaiting for client to connect... *\n************************************\n\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter the Pod-vf02 container, use the mlx5_2 (VF) port to enable the ib_write service connected to pod-vf01, and run the following command"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@pod-vf02:/workspace# ib_write_bw -d mlx5_2 10.20.12.121\n---------------------------------------------------------------------------------------\n                    RDMA_Write BW Test\n Dual-port       : OFF          Device         : mlx5_2\n Number of qps   : 1            Transport type : IB\n Connection type : RC           Using SRQ      : OFF\n PCIe relax order: ON\n ibv_wr* API     : ON\n TX depth        : 128\n CQ Moderation   : 1\n Mtu             : 1024[B]\n Link type       : Ethernet\n GID index       : 3\n Max inline data : 0[B]\n rdma_cm QPs     : OFF\n Data ex. method : Ethernet\n---------------------------------------------------------------------------------------\n local address: LID 0000 QPN 0x03ad PSN 0x17d925 RKey 0x029300 VAddr 0x0073f17a0af000\n GID: 00:00:00:00:00:00:00:00:00:00:255:255:10:20:12:134\n remote address: LID 0000 QPN 0x00e1 PSN 0x146e34 RKey 0x021400 VAddr 0x007bc5c59c3000\n GID: 00:00:00:00:00:00:00:00:00:00:255:255:10:20:12:121\n---------------------------------------------------------------------------------------\n #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]\nConflicting CPU frequency values detected: 800.000000 != 2000.000000. CPU Frequency is not max.\n 65536      5000             2758.40            2758.38            0.044134\n---------------------------------------------------------------------------------------\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"bytes: The size of data transmitted each time is 65536 bytes.\niterations: 5000 iterations are performed.\nBW peak[MB/sec] : The peak bandwidth is 2758.40 MB/s.\nBW average[MB/sec] : The average bandwidth is 2758.38 MB/s.\nMsgRate[Mpps] : The message rate (messages per second) is 0.044134 Mpps.\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"In the preceding result, ibv_wr",(0,o.kt)("em",{parentName:"p"}," API:ON indicates that ibv_wr")," API is used to perform RDMA operations. Transport type: IB: indicates InfiniBand. Note: The IB nic device of the RDMA protocol is used for network communication, which meets expectations."))),(0,o.kt)("p",null,"Next, we test GPU communication, that is, we used GPU collection communication library NCCL to carry out NCCL communication test on VF network ports of two cx5."),(0,o.kt)("h2",{id:"check-gpudirect-rdma"},"Check GPUDirect RDMA"),(0,o.kt)("h3",{id:"install-the-nccl-library-and-compile"},"Install the NCCL Library and Compile"),(0,o.kt)("p",null,"Enter pod-vf01 and pod-vf02 respectively, and install nccl and compile, taking pod-vf01 as an example:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter pod-vf01 "),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"kc exec -it pod-vf07 -n kubeflow -- bash\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter directory /home"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"cd /home/\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Download code"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"git clone https://github.com/NVIDIA/nccl-tests.git\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter directory /home/nccl-tests"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"cd /home/nccl-tests\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Compile"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"make MPI=1 MPI_HOME=/usr/local/mpi\n")))),(0,o.kt)("h3",{id:"setup-mutual-trust-between-pods"},"Setup Mutual Trust between Pods"),(0,o.kt)("h4",{id:"install-openssh"},"Install openssh"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter into pod-vf01"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"kc exec -it pod-vf01 -n kubeflow -- bash\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"apt-update"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"apt update\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"install openssh-server"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"apt install vim openssh-server openssh-client -y\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Repeat the above steps on pod-vf02"))),(0,o.kt)("h4",{id:"generate-rsa-key"},"Generate RSA Key"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Write the contents of the file /root/.ssh/id_rsa.pub to /root/.ssh/authorized_keys in all containers: Copy by hand, one per line"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCVRX69XvcjVlF6a1wqxMMh4ZHDNSzEGwPm7qJdsCkO1JPUpCI+2h44NzRtKBFMf1kfw3d6fOqTh/mVhuhBFTmsQVHaGjj8tffkVzieSJ3RAQYFHKvv4ZPvcN3bsbiqbjE9Syq0JLDahZy1sfTygI0ax6p0uJVAVr03bKy31WVAVi2R6f2Hc6QB5tsHVOzIBK7hCehhNe0wfPW8q0vVK8y36DBLwZC92DLPn77x27c8zT87K2nIuDiVGGkKAu3Fkk6utYswPijlZIW6OjMY1Orx8400eo77wZSybCfZJc25Fr9C14l53db7BV4x1vOcy1teGh8OkOJXwtDo6okQpOJhpuG25FlIpFEgQJZPFkYHOFB+q783+o8vAFd7g3xouS2ARlNnqsO7jB8ZvMTaa89NyKlQKWI3ObVkqjqYvRXlZ/gDhRG2Z5QSV/eVhsY3Dx5IMVPobz4R3rV3/n5QIUXRnMebEAxdfM+VeX+0P11yjPOrYyti7D+p1rYB+3Yf5/0=\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCZRkemmpzBFIl8CQ3lb8uzzMs5H9f7Mo8eHm/IVYRR8FF6X1Gh+z8c88q1fdMgfa9vup2JbRywUeHS2LY9+I3Ln2MK6VB568LjRGJFaGK2vrEcBnaQgPKa9W1xXX+k+93CcAgjECw92nVVKCkfALLUyZEEqmw9Va5iV74cPM7le7VBQOfbOWfogweYuwE7FwRHrFDbueyc9GX1BvzOscSFn/V2YEuQzKOkZQHmcX+OAeV/TepZVKzYzt5mN0Q0P7UWmgn2CD+a4IFjQjXxbPw1zDP+wYmD6jIADks2GNHJu8huCK4IMJQzesMOWoch+2kkK80b0UvAQjTUMwMr2t6CPgOQafEygOr623clROYSSycTQ09ikt9g6SO31UZ4idNcoRcYqomDUs3+pceorer9adLHXM8MmRyRl6wEhCufJ4p4hYhwkL0rLCpBQ011NCP0hzoxUlQyVMnW13ztaKazX65ibunelGdpxJVeI++ldHDD6I3ZdhyP9Yiw767ka2k=\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"To generate a rsa key, run the ssh-keygen -t rsa command and press Enter"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"ssh-keygen -t rsa\n")))),(0,o.kt)("h4",{id:"start-sshd"},"Start sshd"),(0,o.kt)("p",null,"Execute the following commands inside each pod."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"mkdir -p /var/run/sshd && /usr/sbin/sshd -p 20024\n")),(0,o.kt)("h4",{id:"verify-ssh-connectivity"},"Verify SSH Connectivity"),(0,o.kt)("p",null,"Note The ip address of Pod-vf02 is 10.244.2.21. To access pod-vf01, run ssh ",(0,o.kt)("a",{parentName:"p",href:"mailto:root@10.244.2.21"},"root@10.244.2.21")," -p 20024"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"root@pod-vf01:/home# ssh root@10.244.2.21 -p 20024\nWelcome to Ubuntu 22.04.4 LTS (GNU/Linux 6.5.0-41-generic x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/pro\n\nThis system has been minimized by removing packages and content that are\nnot required on a system that users do not log into.\n\nTo restore this content, you can run the 'unminimize' command.\nLast login: Fri Nov 22 06:51:03 2024 from 10.244.2.1\nroot@pod-vf02:~#\n")),(0,o.kt)("p",null,"If it is displayed that you can directly jump to the inside of another pod-vf02 container, it means that the no-secret setting is successful!"),(0,o.kt)("h3",{id:"double-machine-ib-communication"},"Double Machine IB Communication"),(0,o.kt)("p",null,"We use the following command to perform GPU communication by RDMA between two Pods on different nodes."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},'mpirun --allow-run-as-root -H 10.244.1.10:1,10.244.2.21:1 -mca plm_rsh_args "-p 20024" -x NCCL_IB_DISABLE=0 -x NCCL_DEBUG=INFO -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_IB_HCA==mlx5_2 -x UCX_NET_DEVICES=eth0 -x NCCL_NET_GDR_READ=1 ./build/all_reduce_perf -b 2M -e 2G -f 2 -g 1 -n 100 -w 5 \n\n# -x NCCL_IB_HCA==mlx5_2: the name of the VF NIC device\uff1b\n# -H 10.244.1.10:1,10.244.2.21:1  the IP addresses of the two containers, where :1 indicates the number of GPUs.\n')),(0,o.kt)("p",null,"Inside either container, the personal test executes the following command inside the pod-vf02 container:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},'root@pod-vf02:/home/nccl-tests# mpirun --allow-run-as-root -H 10.244.1.10:1,10.244.2.21:1 -mca plm_rsh_args "-p 20024" -x NCCL_IB_DISABLE=0 -x NCCL_DEBUG=INFO -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_IB_HCA==mlx5_2 -x UCX_NET_DEVICES=eth0 -x NCCL_NET_GDR_READ=1 ./build/all_reduce_perf -b 2M -e 2G -f 2 -g 1 -n 100 -w 5\n# nThread 1 nGpus 1 minBytes 2097152 maxBytes 2147483648 step: 2(factor) warmup iters: 5 iters: 100 agg iters: 1 validation: 1 graph: 0\n...............\nNCCL version 2.21.5+cuda12.4\npod-vf07:15718:15718 [0] NCCL INFO cudaDriverVersion 12040\npod-vf07:15718:15718 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\npod-vf07:15718:15718 [0] NCCL INFO Bootstrap : Using eth0:10.244.1.10<0>\npod-vf08:12090:12099 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\npod-vf08:12090:12099 [0] NCCL INFO P2P plugin IBext_v8\npod-vf08:12090:12099 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\npod-vf08:12090:12099 [0] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [RO]; OOB eth0:10.244.2.21<0>\npod-vf08:12090:12099 [0] NCCL INFO Using non-device net plugin version 0\npod-vf08:12090:12099 [0] NCCL INFO Using network IBext_v8\npod-vf07:15718:15726 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\npod-vf07:15718:15726 [0] NCCL INFO P2P plugin IBext_v8\npod-vf07:15718:15726 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\npod-vf07:15718:15726 [0] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [RO]; OOB eth0:10.244.1.10<0>\npod-vf07:15718:15726 [0] NCCL INFO Using non-device net plugin version 0\npod-vf07:15718:15726 [0] NCCL INFO Using network IBext_v8\n..............\n\npod-vf02:12090:12099 [0] NCCL INFO ncclCommInitRank comm 0x5e303a52bd70 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 57000 commId 0xadcb40d61cc1bc4b - Init COMPLETE\n#\n#                                                              out-of-place                       in-place\n#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong\n#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)\n     2097152        524288     float     sum      -1    880.2    2.38    2.38      0    877.1    2.39    2.39      0\n     4194304       1048576     float     sum      -1   1735.3    2.42    2.42      0   1737.9    2.41    2.41      0\n     8388608       2097152     float     sum      -1   3444.5    2.44    2.44      0   3440.1    2.44    2.44      0\n    16777216       4194304     float     sum      -1   6828.2    2.46    2.46      0   6857.6    2.45    2.45      0\n    33554432       8388608     float     sum      -1    13405    2.50    2.50      0    13311    2.52    2.52      0\n    67108864      16777216     float     sum      -1    25563    2.63    2.63      0    25467    2.64    2.64      0\n   134217728      33554432     float     sum      -1    49333    2.72    2.72      0    49034    2.74    2.74      0\n   268435456      67108864     float     sum      -1    96904    2.77    2.77      0    96606    2.78    2.78      0\n   536870912     134217728     float     sum      -1   190709    2.82    2.82      0   190911    2.81    2.81      0\n  1073741824     268435456     float     sum      -1   379615    2.83    2.83      0   380115    2.82    2.82      0\n  2147483648     536870912     float     sum      -1   756857    2.84    2.84      0   757311    2.84    2.84      0\npod-vf01:15718:15718 [0] NCCL INFO comm 0x576eb5d4d740 rank 1 nranks 2 cudaDev 0 busId 2000 - Destroy COMPLETE\npod-vf02:12090:12090 [0] NCCL INFO comm 0x5e303a52bd70 rank 0 nranks 2 cudaDev 0 busId 57000 - Destroy COMPLETE\n# Out of bounds values : 0 OK\n# Avg bus bandwidth    : 2.61937\n')),(0,o.kt)("p",null,"The above test results show that nccl runs successfully, and the GPU communication between containers uses mlx5_2 communication device."),(0,o.kt)("p",null,"The preceding nccl logs show that the IB device mlx5_2 is used."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"pod-vf02:12090:12099 [0] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [RO]; OOB eth0:10.244.2.21<0>\npod-vf01:15718:15726 [0] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [RO]; OOB eth0:10.244.1.10<0>\n")),(0,o.kt)("p",null,"Thus, it is proven that the scheduling framework Koordinator can jointly schedule GPU and RDMA devices, RDMA devices are successfully mounted to the container, and GPU and RDMA maintain topological affinity, which can greatly improve the communication efficiency of GPUs and subsequently enhance the training efficiency of large models."))}m.isMDXComponent=!0},140:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/device-topology-and-network-communication-17c0ffd283d673edf712c00b018cce95.jpg"},5050:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/gpu-rdma-joint-allocation-cf89f80793e0755b8761bee882121ddb.jpg"},5309:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/rdma-nic-topo-9eb0319468b96efbeffa254ad58b1925.png"}}]);