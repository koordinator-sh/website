"use strict";(self.webpackChunkkoordinator_sh=self.webpackChunkkoordinator_sh||[]).push([[3442],{3905:(e,n,a)=>{a.d(n,{Zo:()=>c,kt:()=>h});var t=a(67294);function o(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function r(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function i(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?r(Object(a),!0).forEach((function(n){o(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function l(e,n){if(null==e)return{};var a,t,o=function(e,n){if(null==e)return{};var a,t,o={},r=Object.keys(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||(o[a]=e[a]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var s=t.createContext({}),u=function(e){var n=t.useContext(s),a=n;return e&&(a="function"==typeof e?e(n):i(i({},n),e)),a},c=function(e){var n=u(e.components);return t.createElement(s.Provider,{value:n},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},d=t.forwardRef((function(e,n){var a=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(a),d=o,h=p["".concat(s,".").concat(d)]||p[d]||m[d]||r;return a?t.createElement(h,i(i({ref:n},c),{},{components:a})):t.createElement(h,i({ref:n},c))}));function h(e,n){var a=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=d;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[p]="string"==typeof e?e:o,i[1]=l;for(var u=2;u<r;u++)i[u]=a[u];return t.createElement.apply(null,i)}return t.createElement.apply(null,a)}d.displayName="MDXCreateElement"},27199:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>l,toc:()=>u});var t=a(87462),o=(a(67294),a(3905));const r={},i="Capacity Scheduling - Elastic Quota Management",l={unversionedId:"user-manuals/capacity-scheduling",id:"user-manuals/capacity-scheduling",title:"Capacity Scheduling - Elastic Quota Management",description:"Capacity Scheduling is an ability of koord-scheduler to manage different user's resource usage in a shared-cluster.",source:"@site/docs/user-manuals/capacity-scheduling.md",sourceDirName:"user-manuals",slug:"/user-manuals/capacity-scheduling",permalink:"/zh-Hans/docs/next/user-manuals/capacity-scheduling",draft:!1,editUrl:"https://github.com/koordinator-sh/koordinator.sh/edit/main/docs/user-manuals/capacity-scheduling.md",tags:[],version:"current",lastUpdatedBy:"CYJiang",lastUpdatedAt:1733809631,formattedLastUpdatedAt:"2024\u5e7412\u670810\u65e5",frontMatter:{},sidebar:"docs",previous:{title:"\u7f51\u7edc\u62d3\u6251\u611f\u77e5\u8c03\u5ea6",permalink:"/zh-Hans/docs/next/user-manuals/network-topology-aware-scheduling"},next:{title:"Device Scheduling - Basics",permalink:"/zh-Hans/docs/next/user-manuals/fine-grained-device-scheduling"}},s={},u=[{value:"Introduction",id:"introduction",level:2},{value:"Setup",id:"setup",level:2},{value:"Prerequisite",id:"prerequisite",level:3},{value:"Installation",id:"installation",level:3},{value:"Configurations",id:"configurations",level:3},{value:"Use Capacity-Scheduling",id:"use-capacity-scheduling",level:2},{value:"Quick Start by Label",id:"quick-start-by-label",level:3},{value:"Quick Start by Namespace",id:"quick-start-by-namespace",level:3},{value:"Quota Debug API",id:"quota-debug-api",level:3},{value:"Advanced Configurations",id:"advanced-configurations",level:3},{value:"WebHook Verify",id:"webhook-verify",level:3},{value:"used &gt; runtime revoke",id:"used--runtime-revoke",level:3},{value:"multi quota tree",id:"multi-quota-tree",level:3}],c={toc:u},p="wrapper";function m(e){let{components:n,...a}=e;return(0,o.kt)(p,(0,t.Z)({},c,a,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"capacity-scheduling---elastic-quota-management"},"Capacity Scheduling - Elastic Quota Management"),(0,o.kt)("p",null,"Capacity Scheduling is an ability of koord-scheduler to manage different user's resource usage in a shared-cluster."),(0,o.kt)("h2",{id:"introduction"},"Introduction"),(0,o.kt)("p",null,"When several users or teams share a cluster, fairness of resource allocation is very important. the Koordinator provides\nmulti-hierarchy elastic quota management mechanism for the scheduler. "),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"It supports configuring quota groups in a tree structure, which is similar to the organizational structure of most companies."),(0,o.kt)("li",{parentName:"ul"},'It supports the borrowing / returning of resources between different quota groups, for better resource utilization efficiency.\nThe busy quota groups can automatically temporarily borrow the resources from the idle quota groups, which can improve the\nutilization of the cluster. At the same time, when the idle quota group turn into the busy quota group, it can also automatically\ntake back the "lent-to" resources.'),(0,o.kt)("li",{parentName:"ul"},"It considers the resource fairness between different quota groups. When the busy quota groups borrow the\nresources from the idle quota groups, the resources can be allocated to the busy quota groups under some fair rules.")),(0,o.kt)("h2",{id:"setup"},"Setup"),(0,o.kt)("h3",{id:"prerequisite"},"Prerequisite"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Kubernetes >= 1.18"),(0,o.kt)("li",{parentName:"ul"},"Koordinator >= 0.71")),(0,o.kt)("h3",{id:"installation"},"Installation"),(0,o.kt)("p",null,"Please make sure Koordinator components are correctly installed in your cluster. If not, please refer to ",(0,o.kt)("a",{parentName:"p",href:"/docs/installation"},"Installation"),"."),(0,o.kt)("h3",{id:"configurations"},"Configurations"),(0,o.kt)("p",null,"Capacity-Scheduling is ",(0,o.kt)("em",{parentName:"p"},"Enabled")," by default. You can use it without any modification on the koord-descheduler config."),(0,o.kt)("p",null,"If you want to use multi quota trees, you need to set feature-gate ",(0,o.kt)("inlineCode",{parentName:"p"},"MultiQuotaTree")," to true in koord-manager and koord-scheduler."),(0,o.kt)("h2",{id:"use-capacity-scheduling"},"Use Capacity-Scheduling"),(0,o.kt)("h3",{id:"quick-start-by-label"},"Quick Start by Label"),(0,o.kt)("p",null,"1.Create an ElasticQuota ",(0,o.kt)("inlineCode",{parentName:"p"},"quota-example")," with the YAML file below."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/parent: ""\n    quota.scheduling.koordinator.sh/is-parent: "false"\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl apply -f quota-example.yaml\n  elasticquota.scheduling.sigs.k8s.io/quota-example created\n\n$ kubectl get eqs -n default\n  NAME     AGE\n  test-d   2s\n")),(0,o.kt)("p",null,"2.Create a Pod ",(0,o.kt)("inlineCode",{parentName:"p"},"pod-example")," with the YAML file below."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/name: "quota-example"\nspec:\n  schedulerName: koord-scheduler\n  containers:\n  - command:\n    - sleep\n    - 365d\n    image: busybox\n    imagePullPolicy: IfNotPresent\n    name: curlimage\n    resources:\n      limits:\n        cpu: 40m\n        memory: 40Mi\n      requests:\n        cpu: 40m\n        memory: 40Mi\n    terminationMessagePath: /dev/termination-log\n    terminationMessagePolicy: File\n  restartPolicy: Always\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl apply -f pod-example.yaml\n  pod/pod-example created\n")),(0,o.kt)("p",null,"3.Verify ",(0,o.kt)("inlineCode",{parentName:"p"},"quota-example")," has changed."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl get eqs -n default quota-example -o yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'kind: ElasticQuota\nmetadata:\n  annotations:\n    quota.scheduling.koordinator.sh/request: \'{"cpu":"40m","memory":"40Mi"}\'\n    quota.scheduling.koordinator.sh/runtime: \'{"cpu":"40m","memory":"40Mi"}\'\n    quota.scheduling.koordinator.sh/shared-weight: \'{"cpu":"40","memory":"40Gi"}\'\n  creationTimestamp: "2022-10-08T09:26:38Z"\n  generation: 2\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: "false"\n    quota.scheduling.koordinator.sh/parent: root\n    manager: koord-scheduler\n    operation: Update\n    time: "2022-10-08T09:26:50Z"\n  name: quota-example\n  namespace: default\n  resourceVersion: "39012008"\nspec:\n  max:\n    cpu: "40"\n    memory: 40Gi\n  min:\n    cpu: "10"\n    memory: 20Mi\nstatus:\n  used:\n    cpu: 40m\n    memory: 40Mi\n')),(0,o.kt)("h3",{id:"quick-start-by-namespace"},"Quick Start by Namespace"),(0,o.kt)("p",null,"1.Create a Namespace"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl create ns quota-example\n  namespace/quota-example created\n")),(0,o.kt)("p",null,"2.Create a ElasticQuota ",(0,o.kt)("inlineCode",{parentName:"p"},"quota-example")," with the YAML file below."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-example\n  namespace: quota-example\n  labels:\n    quota.scheduling.koordinator.sh/parent: ""\n    quota.scheduling.koordinator.sh/is-parent: "false"\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl apply -f quota-example.yaml\n  elasticquota.scheduling.sigs.k8s.io/quota-example created\n\n$ kubectl get eqs -n quota-example\n  NAME     AGE\n  test-d   2s\n")),(0,o.kt)("p",null,"2.Create a Pod ",(0,o.kt)("inlineCode",{parentName:"p"},"pod-example")," with the YAML file below."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\n  namespace: quota-example\nspec:\n  schedulerName: koord-scheduler\n  containers:\n  - command:\n    - sleep\n    - 365d\n    image: busybox\n    imagePullPolicy: IfNotPresent\n    name: curlimage\n    resources:\n      limits:\n        cpu: 40m\n        memory: 40Mi\n      requests:\n        cpu: 40m\n        memory: 40Mi\n    terminationMessagePath: /dev/termination-log\n    terminationMessagePolicy: File\n  restartPolicy: Always\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl apply -f pod-example.yaml\n  pod/pod-example created\n")),(0,o.kt)("p",null,"3.Verify ",(0,o.kt)("inlineCode",{parentName:"p"},"quota-example")," has changed."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl get eqs -n quota-example quota-example -o yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'kind: ElasticQuota\nmetadata:\n  annotations:\n    quota.scheduling.koordinator.sh/request: \'{"cpu":"40m","memory":"40Mi"}\'\n    quota.scheduling.koordinator.sh/runtime: \'{"cpu":"40m","memory":"40Mi"}\'\n    quota.scheduling.koordinator.sh/shared-weight: \'{"cpu":"40","memory":"40Gi"}\'\n  creationTimestamp: "2022-10-08T09:26:38Z"\n  generation: 2\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: "false"\n    quota.scheduling.koordinator.sh/parent: root\n    manager: koord-scheduler\n    operation: Update\n    time: "2022-10-08T09:26:50Z"\n  name: quota-example\n  namespace: quota-example\n  resourceVersion: "39012008"\nspec:\n  max:\n    cpu: "40"\n    memory: 40Gi\n  min:\n    cpu: "10"\n    memory: 20Mi\nstatus:\n  used:\n    cpu: 40m\n    memory: 40Mi\n')),(0,o.kt)("h3",{id:"quota-debug-api"},"Quota Debug API"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl -n koordinator-system get lease koord-scheduler --no-headers | awk '{print $2}' | cut -d'_' -f1 | xargs -I {} kubectl -n koordinator-system get pod {} -o wide --no-headers | awk '{print $6}'\n  10.244.0.64\n\n$ curl 10.244.0.64:10251/apis/v1/plugins/ElasticQuota/quota/quota-example\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "allowLentResource": true,\n    "autoScaleMin": {\n        "cpu": "10",\n        "memory": "20Mi",\n    },\n    "isParent": false,\n    "max": {\n        "cpu": "40",\n        "memory": "40Gi",\n    },\n    "min": {\n        "cpu": "10",\n        "memory": "20Mi",\n    },\n    "name": "quota-example",\n    "parentName": "root",\n    "podCache": {\n        "pod-example": {\n            "isAssigned": true,\n            "resource": {\n                "cpu": "40m",\n                "memory": "40Mi"\n            }\n        }\n    },\n    "request": {\n        "cpu": "40m",\n        "memory": "40Mi"\n    },\n    "runtime": {\n        "cpu": "40m",\n        "memory": "41943040",\n    },\n    "runtimeVersion": 39,\n    "sharedWeight": {\n        "cpu": "40",\n        "memory": "40Gi",\n    },\n    "used": {\n        "cpu": "40m",\n        "memory": "40Mi"\n    }\n}\n')),(0,o.kt)("p",null,"The main different with yaml is that we can find all quota's pods and its status in ",(0,o.kt)("inlineCode",{parentName:"p"},"podCache"),"."),(0,o.kt)("h3",{id:"advanced-configurations"},"Advanced Configurations"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: false\n    quota.scheduling.koordinator.sh/parent: "parent"\n    quota.scheduling.koordinator.sh/allow-lent-resource: true\n  annotations:\n    quota.scheduling.koordinator.sh/shared-weight: \'{"cpu":"40","memory":"40Gi"}\'\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n')),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"quota.scheduling.koordinator.sh/is-parent"),' is disposed by the user. It reflects the "child\\parent" attribute of the quota group. Default is child.'),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"quota.scheduling.koordinator.sh/parent")," is disposed by the user. It reflects the parent quota name. Default is root."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"quota.scheduling.koordinator.sh/shared-weight"),' is disposed by the user. It reflects the ability to share the "lent to" resource. Default equals to "max".'),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"quota.scheduling.koordinator.sh/allow-lent-resource"),' is disposed by the user. It reflects whether quota group allows lent unused "min" to others.')),(0,o.kt)("h3",{id:"webhook-verify"},"WebHook Verify"),(0,o.kt)("p",null,'1.Except for the first level quota group, we require that the sum of "min" of all sub quota groups should be less than or\nequal to the "min" of parent group. '),(0,o.kt)("p",null,"first create parent quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-parent-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: true\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n")),(0,o.kt)("p",null,"then create child quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: false\n    quota.scheduling.koordinator.sh/parent: "quota-parent-example"\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 20\n    memory: 20Mi\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'kubectl apply -f quota-example.yaml\nError from server: error when creating "quota-example.yaml": admission webhook "vquota.kb.io" denied the request: checkMinQuotaSum allChildren SumMinQuota > parentMinQuota, parent: quota-parent-example\n')),(0,o.kt)("p",null,"2.Parent and child's min\\max resource key must same.\nfirst create parent quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-parent-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: true\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n")),(0,o.kt)("p",null,"then create child quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: false\n    quota.scheduling.koordinator.sh/parent: "quota-parent-example"\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n    test: 200\n  min:\n    cpu: 10\n    memory: 20Mi\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'$ kubectl apply -f quota-example.yaml\n  Error from server: error when creating "quota-example.yaml": admission webhook "vquota.kb.io" denied the request: checkSubAndParentGroupMaxQuotaKeySame failed: quota-parent-example\'s key is not the same with quota-example\n')),(0,o.kt)("p",null,"3.Parent group cannot run pod."),(0,o.kt)("p",null,"first create parent quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-parent-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: true\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n")),(0,o.kt)("p",null,"then create pod:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/name: "quota-parent-example"\nspec:\n  schedulerName: koord-scheduler\n  containers:\n  - command:\n    - sleep\n    - 365d\n    image: busybox\n    imagePullPolicy: IfNotPresent\n    name: curlimage\n    resources:\n      limits:\n        cpu: 40m\n        memory: 40Mi\n      requests:\n        cpu: 40m\n        memory: 40Mi\n    terminationMessagePath: /dev/termination-log\n    terminationMessagePolicy: File\n  restartPolicy: Always\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'$ kubectl apply -f pod-example_xb.yaml\n  Error from server: error when creating "pod-example.yaml": admission webhook "vpod.kb.io" denied the request: pod can not be linked to a parentQuotaGroup,quota:quota-parent-example, pod:pod-example\n')),(0,o.kt)("p",null,"4.The parent of node can only be parent group, not child group."),(0,o.kt)("p",null,"first create parent quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-parent-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: false\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n")),(0,o.kt)("p",null,"then create child quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: false\n    quota.scheduling.koordinator.sh/parent: "quota-parent-example"\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n    test: 200\n  min:\n    cpu: 10\n    memory: 20Mi\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'$ kubectl apply -f quota-example.yaml\n  Error from server: error when creating "elastic-quota-example_xb.yaml": admission webhook "vquota.kb.io" denied the request: quota-example has parentName quota-parent-example but the parentQuotaInfo\'s IsParent is false\n')),(0,o.kt)("p",null,"5.A quota group can't be converted on the attribute of parent group\\child group."),(0,o.kt)("p",null,"first create parent quota:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  name: quota-parent-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: true\nspec:\n  max:\n    cpu: 40\n    memory: 40Gi\n  min:\n    cpu: 10\n    memory: 20Mi\n")),(0,o.kt)("p",null,"then modify ",(0,o.kt)("inlineCode",{parentName:"p"},"quota.scheduling.koordinator.sh/is-parent:false"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'$ kubectl apply -f quota-parent-example.yaml\n  elastic-quota-example_xb_parent.yaml": admission webhook "vquota.kb.io" denied the request: IsParent is forbidden modify now, quotaName:quota-parent-example\n')),(0,o.kt)("h3",{id:"used--runtime-revoke"},"used > runtime revoke"),(0,o.kt)("p",null,"We offer a config to control if quota's used > runtime, we allow the scheduler to delete over-resource-used pod from\nlow priority to high priority. you should follow the below config of ",(0,o.kt)("inlineCode",{parentName:"p"},"koord-scheduler-config.yaml")," in helm."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: koord-scheduler-config\n  namespace: {{ .Values.installation.namespace }}\ndata:\n  koord-scheduler-config: |\n    apiVersion: kubescheduler.config.k8s.io/v1beta2\n    kind: KubeSchedulerConfiguration\n    leaderElection:\n      leaderElect: true\n      resourceLock: leases\n      resourceName: koord-scheduler\n      resourceNamespace: {{ .Values.installation.namespace }}\n    profiles:\n      - pluginConfig:\n        - name: ElasticQuota\n          args:\n            apiVersion: kubescheduler.config.k8s.io/v1beta2\n            kind: ElasticQuotaArgs\n            quotaGroupNamespace: {{ .Values.installation.namespace }}\n            enableCheckParentQuota: true\n            monitorAllQuotas: true\n            revokePodInterval: 60s\n            delayEvictTime: 300s\n        plugins:\n          queueSort:\n            disabled:\n              - name: "*"\n            enabled:\n              - name: Coscheduling\n          preFilter:\n            enabled:\n              - name: NodeNUMAResource\n              - name: DeviceShare\n              - name: Reservation\n              - name: Coscheduling\n              - name: ElasticQuota\n          filter:\n              ...\n')),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"enableCheckParentQuota")," check parentQuotaGroups' used and runtime Quota. Default is false."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"monitorAllQuotas"),' enable "used > runtime revoke" logic. Default is false.'),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"revokePodInterval")," check loop time interval."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"delayEvictTime"),' when "used > runtime" continues over ',(0,o.kt)("inlineCode",{parentName:"li"},"delayEvictTime")," will really trigger eviction.")),(0,o.kt)("p",null,"To let scheduler can really delete the pod successfully, you should config the ",(0,o.kt)("inlineCode",{parentName:"p"},"rbac/koord-scheduler.yaml")," as below in helm."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: koord-scheduler-role\nrules:\n{{- if semverCompare "<= 1.20-0" .Capabilities.KubeVersion.Version }}\n- apiGroups:\n  - ""\n  resources:\n  - namespaces\n  verbs:\n  - get\n  - list\n  - watch\n{{- end }}\n- apiGroups:\n  - coordination.k8s.io\n  resources:\n  - leases\n  verbs:\n  - create\n  - get\n  - update\n- apiGroups:\n  - ""\n  resources:\n  - pods\n  verbs:\n  - patch\n  - update\n  - delete\n- apiGroups:\n  - ""\n  resources:\n  - pods/eviction\n  verbs:\n  - create\n- apiGroups:\n  ...\n')),(0,o.kt)("p",null,"To prevent Pods from being revoked, you can add label ",(0,o.kt)("inlineCode",{parentName:"p"},"quota.scheduling.koordinator.sh/preemptible: false")," to the Pod:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\n  namespace: default\n  labels:\n    quota.scheduling.koordinator.sh/name: "quota-example"\n    quota.scheduling.koordinator.sh/preemptible: false\nspec:\n...\n')),(0,o.kt)("p",null,"In this case, the Pod is not allowed to use resources exceeding the ",(0,o.kt)("inlineCode",{parentName:"p"},"Min"),'.\nSince the "Min" resources are the guaranteed resources, the Pod will not be evicted.'),(0,o.kt)("h3",{id:"multi-quota-tree"},"multi quota tree"),(0,o.kt)("p",null,"If you want to use multi quota trees, you need to set feature-gate ",(0,o.kt)("inlineCode",{parentName:"p"},"MultiQuotaTree")," to true in koord-manager and koord-scheduler."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"create quota profile ",(0,o.kt)("inlineCode",{parentName:"li"},"cn-hangzhou-k-nodepool")," and ",(0,o.kt)("inlineCode",{parentName:"li"},"cn-hangzhou-g-nodepool")," with the YAML file below.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: quota.koordinator.sh/v1alpha1\nkind: ElasticQuotaProfile\nmetadata:\n  labels:\n    topology.kubernetes.io/region: cn-hangzhou\n    topology.kubernetes.io/zone: cn-hangzhou-k\n  name: cn-hangzhou-k-nodepool\n  namespace: kube-system\nspec:\n  nodeSelector:\n    matchLabels:\n      topology.kubernetes.io/region: cn-hangzhou\n      topology.kubernetes.io/zone: cn-hangzhou-k\n  quotaLabels:\n    quota.scheduling.koordinator.sh/is-parent: "true"\n    topology.kubernetes.io/region: cn-hangzhou\n    topology.kubernetes.io/zone: cn-hangzhou-k\n  quotaName: cn-hangzhou-k-root-quota\n---\napiVersion: quota.koordinator.sh/v1alpha1\nkind: ElasticQuotaProfile\nmetadata:\n  labels:\n    topology.kubernetes.io/region: cn-hangzhou\n    topology.kubernetes.io/zone: cn-hangzhou-g\n  name: cn-hangzhou-g-nodepool\n  namespace: kube-system\nspec:\n  nodeSelector:\n    matchLabels:\n      topology.kubernetes.io/region: cn-hangzhou\n      topology.kubernetes.io/zone: cn-hangzhou-g\n  quotaLabels:\n    quota.scheduling.koordinator.sh/is-parent: "true"\n    topology.kubernetes.io/region: cn-hangzhou\n    topology.kubernetes.io/zone: cn-hangzhou-g\n  quotaName: cn-hangzhou-g-root-quota\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl apply -f quota-profile.yaml\n  elasticquotaprofile.quota.koordinator.sh/cn-hangzhou-k-nodepool created\n  elasticquotaprofile.quota.koordinator.sh/cn-hangzhou-g-nodepool created\n")),(0,o.kt)("p",null,"We has three nodes. two nodes is in cn-hangzhou-k, one node is in cn-hangzhou-g. Every node has 4 cpus(3.9 is allocatable) and 15.3Gi(12.52Gi is allocatable) memory."),(0,o.kt)("p",null,"The quota profile ",(0,o.kt)("inlineCode",{parentName:"p"},"cn-hangzhou-k-nodepool")," select the nodes in cn-hangzhou-k.\nThe quota profile ",(0,o.kt)("inlineCode",{parentName:"p"},"cn-hangzhou-g-nodepool")," select the nodes in cn-hangzhou-g."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl --kubeconfig kubeconfig get nodes -L topology.kubernetes.io/zone\nNAME                          STATUS   ROLES    AGE    VERSION            ZONE\ncn-hangzhou.192.168.112.189   Ready    <none>   83m    v1.28.3-aliyun.1   cn-hangzhou-g\ncn-hangzhou.192.168.14.209    Ready    <none>   102m   v1.28.3-aliyun.1   cn-hangzhou-k\ncn-hangzhou.192.168.14.210    Ready    <none>   102m   v1.28.3-aliyun.1   cn-hangzhou-k\n")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},"the profile controller will generate the root quota ",(0,o.kt)("inlineCode",{parentName:"li"},"cn-hangzhou-k-root-quota")," and ",(0,o.kt)("inlineCode",{parentName:"li"},"cn-hangzhou-g-root-quota"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$  kubectl -nkube-system get eq  cn-hangzhou-k-root-quota cn-hangzhou-g-root-quota\nNAME                              AGE\ncn-hangzhou-k-root-quota   24m\ncn-hangzhou-g-root-quota   24m\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  annotations:\n    quota.scheduling.koordinator.sh/shared-weight: \'{"cpu":"4611686018427387","memory":"4611686018427387"}\'\n    quota.scheduling.koordinator.sh/total-resource: \'{"cpu":"7800m","ephemeral-storage":"227102691772","hugepages-1Gi":"0","hugepages-2Mi":"0","kubernetes.io/batch-cpu":"4458","kubernetes.io/batch-memory":"13451995003","kubernetes.io/mid-cpu":"0","kubernetes.io/mid-memory":"0","memory":"26264816Ki","pods":"46"}\'\n  creationTimestamp: "2024-03-19T11:11:24Z"\n  generation: 1\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: "true"\n    quota.scheduling.koordinator.sh/is-root: "true"\n    quota.scheduling.koordinator.sh/parent: koordinator-root-quota\n    quota.scheduling.koordinator.sh/profile: cn-hangzhou-k-nodepool\n    quota.scheduling.koordinator.sh/tree-id: "18340441938858026940"\n    topology.kubernetes.io/region: cn-hangzhou\n    topology.kubernetes.io/zone: cn-hangzhou-k\n  name: cn-hangzhou-k-root-quota\n  namespace: kube-system\n  resourceVersion: "26949"\n  uid: cf9c35e7-5f44-42a5-ba9d-1a365903b7a8\nspec:\n  max:\n    cpu: "4611686018427387"\n    memory: "4611686018427387"\n  min:\n    cpu: 7800m\n    memory: 26264816Ki\nstatus: {}\n---\napiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  annotations:\n    quota.scheduling.koordinator.sh/shared-weight: \'{"cpu":"4611686018427387","memory":"4611686018427387"}\'\n    quota.scheduling.koordinator.sh/total-resource: \'{"cpu":"3900m","ephemeral-storage":"113781462033","hugepages-1Gi":"0","hugepages-2Mi":"0","kubernetes.io/batch-cpu":"2276","kubernetes.io/batch-memory":"7120693060","kubernetes.io/mid-cpu":"0","kubernetes.io/mid-memory":"0","memory":"12903364Ki","pods":"23"}\'\n  creationTimestamp: "2024-03-19T11:11:30Z"\n  generation: 1\n  labels:\n    quota.scheduling.koordinator.sh/is-parent: "true"\n    quota.scheduling.koordinator.sh/is-root: "true"\n    quota.scheduling.koordinator.sh/parent: koordinator-root-quota\n    quota.scheduling.koordinator.sh/profile: cn-hangzhou-g-nodepool\n    quota.scheduling.koordinator.sh/tree-id: "8589367430557242040"\n    topology.kubernetes.io/region: cn-hangzhou\n    topology.kubernetes.io/zone: cn-hangzhou-g\n  name: cn-hangzhou-g-root-quota\n  namespace: kube-system\n  resourceVersion: "40568"\n  uid: 8d886c21-c3c7-40b2-a944-b2f6117586b3\nspec:\n  max:\n    cpu: "4611686018427387"\n    memory: "4611686018427387"\n  min:\n    cpu: 3900m\n    memory: 12903364Ki\nstatus: {}\n')),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"quota.scheduling.koordinator.sh/total-resource")," is updated by the controller. It'll sum the node resources. And the quota min is equal the total resources."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"quota.scheduling.koordinator.sh/is-root")," means the root quota of the quota tree."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"quota.scheduling.koordinator.sh/tree-id")," means the tree id.")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"create child quota ",(0,o.kt)("inlineCode",{parentName:"li"},"test-child")," with the YAML file below. the parent is ",(0,o.kt)("inlineCode",{parentName:"li"},"cn-hangzhou-k-root-quota"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  annotations:\n  labels:\n    quota.scheduling.koordinator.sh/parent: cn-hangzhou-k-root-quota\n  name: test-child\n  namespace: kube-system\nspec:\n  max:\n    cpu: 3\n    memory: 6Gi\n  min:\n    cpu: 3\n    memory: 6Gi\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl apply -f test-child.yaml\nelasticquota.scheduling.sigs.k8s.io/test-child created\n")),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"Create a pod ",(0,o.kt)("inlineCode",{parentName:"li"},"pod-example")," with the YAML file below.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\n  namespace: kube-system\n  labels:\n    quota.scheduling.koordinator.sh/name: "test-child"\nspec:\n  schedulerName: koord-scheduler\n  containers:\n  - command:\n    - sleep\n    - 365d\n    image: busybox\n    imagePullPolicy: IfNotPresent\n    name: curlimage\n    resources:\n      limits:\n        cpu: 1\n        memory: 2Gi\n      requests:\n        cpu: 1\n        memory: 2Gi\n')),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"check the pod the quota info")),(0,o.kt)("p",null,"The node is scheduled to the node cn-hangzhou.192.168.14.209. Indeed the quota profile nodeSelector is injected the the pod node affinity."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    k8s.aliyun.com/pod-ips: 192.168.15.4\n  creationTimestamp: "2024-03-19T11:17:36Z"\n  labels:\n    quota.scheduling.koordinator.sh/name: test-child\n  name: pod-example\n  namespace: kube-system\n  resourceVersion: "28417"\n  uid: 021364da-820b-490c-843e-a6b2d51ed023\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: topology.kubernetes.io/region\n            operator: In\n            values:\n            - cn-hangzhou\n          - key: topology.kubernetes.io/zone\n            operator: In\n            values:\n            - cn-hangzhou-k\n  containers:\n  - command:\n    - sleep\n    - 365d\n    image: busybox\n    imagePullPolicy: IfNotPresent\n    name: curlimage\n    resources:\n      limits:\n        cpu: "1"\n        memory: 2Gi\n      requests:\n        cpu: "1"\n        memory: 2Gi\n    terminationMessagePath: /dev/termination-log\n    terminationMessagePolicy: File\n    volumeMounts:\n    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n      name: kube-api-access-mf6vc\n      readOnly: true\n  dnsPolicy: ClusterFirst\n  enableServiceLinks: true\n  nodeName: cn-hangzhou.192.168.14.209\n  preemptionPolicy: PreemptLowerPriority\n  priority: 0\n  restartPolicy: Always\n  schedulerName: koord-scheduler\n  securityContext: {}\n  serviceAccount: default\n  serviceAccountName: default\n  terminationGracePeriodSeconds: 30\n  tolerations:\n  - effect: NoExecute\n    key: node.kubernetes.io/not-ready\n    operator: Exists\n    tolerationSeconds: 300\n  - effect: NoExecute\n    key: node.kubernetes.io/unreachable\n    operator: Exists\n    tolerationSeconds: 300\n  volumes:\n  - name: kube-api-access-mf6vc\n    projected:\n      defaultMode: 420\n      sources:\n      - serviceAccountToken:\n          expirationSeconds: 3607\n          path: token\n      - configMap:\n          items:\n          - key: ca.crt\n            path: ca.crt\n          name: kube-root-ca.crt\n      - downwardAPI:\n          items:\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n            path: namespace\n')),(0,o.kt)("p",null,"the quota ",(0,o.kt)("inlineCode",{parentName:"p"},"test-child")," used 1 cpu and 2Gi memory"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: scheduling.sigs.k8s.io/v1alpha1\nkind: ElasticQuota\nmetadata:\n  annotations:\n    quota.scheduling.koordinator.sh/child-request: \'{"cpu":"1","memory":"2Gi"}\'\n    quota.scheduling.koordinator.sh/request: \'{"cpu":"1","memory":"2Gi"}\'\n    quota.scheduling.koordinator.sh/runtime: \'{"cpu":"1","memory":"2Gi"}\'\n    quota.scheduling.koordinator.sh/shared-weight: \'{"cpu":"3","memory":"6Gi"}\'\n  creationTimestamp: "2024-03-19T11:16:11Z"\n  generation: 2\n  labels:\n    quota.scheduling.koordinator.sh/parent: cn-hangzhou-k-root-quota\n    quota.scheduling.koordinator.sh/tree-id: "18340441938858026940"\n  name: test-child\n  namespace: kube-system\n  resourceVersion: "28358"\n  uid: e929c26c-d8ff-420a-a300-f1e801370f81\nspec:\n  max:\n    cpu: "3"\n    memory: 6Gi\n  min:\n    cpu: "3"\n    memory: 6Gi\nstatus:\n  used:\n    cpu: "1"\n    memory: 2Gi\n')))}m.isMDXComponent=!0}}]);